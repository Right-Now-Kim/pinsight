import math
import streamlit as st
import pandas as pd
import io
import zipfile
from collections import defaultdict
import time
import matplotlib.pyplot as plt
from matplotlib.patches import Rectangle
from matplotlib_venn import venn2, venn3, venn2_circles, venn3_circles # ë²¤ë‹¤ì´ì–´ê·¸ë¨ ì‚¬ìš© ì‹œ (í•„ìš”ì‹œ ì„¤ì¹˜)

# Selenium ê´€ë ¨ import
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, NoSuchElementException, ElementClickInterceptedException
from selenium.webdriver.chrome.service import Service as ChromeService
from webdriver_manager.chrome import ChromeDriverManager
import re
import os # íŒŒì¼ëª… ì²˜ë¦¬ ë“±

st.set_page_config(page_title="Pinsight CSV & Webtoon Utility", layout="wide") # ì•± ì œëª© ë³€ê²½
st.title("Pinsight CSV & ì›¹íˆ° ì •ë³´ ì¶”ì¶œ ë„êµ¬") # ì•± ì œëª© ë³€ê²½

# ------------------------------------------------------------------------------
# A. CSV ì—…ë¡œë“œ ì²˜ë¦¬
# ------------------------------------------------------------------------------
st.header("ğŸ“„ CSV íŒŒì¼ ê´€ë¦¬") # í—¤ë”ë¡œ ë³€ê²½
st.subheader("1) CSV ì—…ë¡œë“œ")

uploaded_files = st.file_uploader(
    "ì—¬ê¸°ì— CSV íŒŒì¼ë“¤ì„ ë“œë˜ê·¸í•˜ê±°ë‚˜, 'Browse files' ë²„íŠ¼ì„ ëˆŒëŸ¬ ì„ íƒí•˜ì„¸ìš”. (ê° CSVëŠ” ì²« ë²ˆì§¸ ì—´ì— IDê°€ ìˆì–´ì•¼ í•©ë‹ˆë‹¤)",
    type=["csv"],
    accept_multiple_files=True
)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” (ì•± ì‹¤í–‰ ì‹œ í•œ ë²ˆë§Œ)
if "csv_dataframes" not in st.session_state:
    st.session_state["csv_dataframes"] = {}
if "file_names" not in st.session_state:
    st.session_state["file_names"] = {}

if st.button("CSV ë¡œë“œí•˜ê¸°", key="load_csv_button"):
    if uploaded_files:
        loaded_count = 0
        for uploaded_file in uploaded_files:
            # ì´ë¯¸ ë¡œë“œëœ íŒŒì¼ëª…ì¸ì§€ í™•ì¸ (ë®ì–´ì“°ê¸° ë°©ì§€ ë˜ëŠ” ì‚¬ìš©ìì—ê²Œ ì•Œë¦¼)
            if uploaded_file.name in st.session_state["csv_dataframes"]:
                st.warning(f"'{uploaded_file.name}' íŒŒì¼ì€ ì´ë¯¸ ë¡œë“œë˜ì–´ ìˆìŠµë‹ˆë‹¤. ìƒˆë¡œ ë¡œë“œí•˜ë ¤ë©´ ê¸°ì¡´ íŒŒì¼ì„ ì‚­ì œ í›„ ì§„í–‰í•´ì£¼ì„¸ìš”.", icon="âš ï¸")
                continue # ë‹¤ìŒ íŒŒì¼ë¡œ ë„˜ì–´ê°

            try:
                # CSVë¥¼ ì½ì„ ë•Œ, ì²« ë²ˆì§¸ ì—´ë§Œ ì‚¬ìš©í•˜ê³  ë‚˜ë¨¸ì§€ëŠ” ë¬´ì‹œí•˜ê±°ë‚˜, í•„ìš”ì— ë”°ë¼ ì²˜ë¦¬
                # ì—¬ê¸°ì„œëŠ” ëª¨ë“  ì—´ì„ ì½ë˜, UIDëŠ” ì²« ë²ˆì§¸ ì—´ë¡œ ê°€ì •
                df = pd.read_csv(uploaded_file, header=None, dtype=str) # ëª¨ë“  ë°ì´í„°ë¥¼ ë¬¸ìì—´ë¡œ ì½ê¸° (UID ì¼ê´€ì„±)
                if df.empty or df.shape[1] == 0:
                    st.error(f"'{uploaded_file.name}' íŒŒì¼ì´ ë¹„ì–´ìˆê±°ë‚˜ ìœ íš¨í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    continue

                st.session_state["csv_dataframes"][uploaded_file.name] = df
                st.session_state["file_names"][uploaded_file.name] = uploaded_file.name # ì´ˆê¸° íŒŒì¼ëª… ì„¤ì •
                st.success(f"'{uploaded_file.name}': ì—…ë¡œë“œ & ë¡œë“œ ì„±ê³µ (í–‰ ìˆ˜: {len(df)})")
                loaded_count +=1
            except pd.errors.EmptyDataError:
                st.error(f"'{uploaded_file.name}': íŒŒì¼ì´ ë¹„ì–´ìˆì–´ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            except Exception as e:
                st.error(f"'{uploaded_file.name}': ë¡œë“œ ì‹¤íŒ¨ - {e}")
        if loaded_count > 0 :
            st.rerun() # íŒŒì¼ ëª©ë¡ ì¦‰ì‹œ ì—…ë°ì´íŠ¸
    else:
        st.warning("ì—…ë¡œë“œëœ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")

# ------------------------------------------------------------------------------
# B. ì—…ë¡œë“œëœ íŒŒì¼ ëª©ë¡ í‘œì‹œ (íŒŒì¼ëª… ë³€ê²½ ë° ì‚­ì œ ê¸°ëŠ¥)
# ------------------------------------------------------------------------------
if st.session_state["csv_dataframes"]:
    st.write("### ì—…ë¡œë“œëœ íŒŒì¼ ëª©ë¡ ë° ê´€ë¦¬")
    
    # ì‚­ì œí•  íŒŒì¼ í‚¤ë¥¼ ì„ì‹œ ì €ì¥ (ìˆœíšŒ ì¤‘ ë”•ì…”ì…”ë„ˆë¦¬ ë³€ê²½ ë°©ì§€)
    keys_to_delete_from_session = []

    for original_name in list(st.session_state["csv_dataframes"].keys()): # ìˆœíšŒ ì¤‘ ë³€ê²½ ë°©ì§€
        if original_name not in st.session_state["csv_dataframes"]: continue # ì´ë¯¸ ì‚­ì œëœ ê²½ìš°

        df_display = st.session_state["csv_dataframes"][original_name]
        
        col_name, col_info, col_download, col_delete = st.columns([3, 2, 1.5, 1])

        with col_name:
            # íŒŒì¼ëª… ë³€ê²½ ì…ë ¥ í•„ë“œ
            current_display_name = st.session_state["file_names"].get(original_name, original_name)
            new_display_name = st.text_input(
                f"íŒŒì¼ëª… (ì›ë³¸: {original_name})",
                value=current_display_name,
                key=f"text_input_filename_{original_name}"
            )
            if new_display_name != current_display_name:
                # ìƒˆ íŒŒì¼ëª…ì´ ë‹¤ë¥¸ íŒŒì¼ì˜ í˜„ì¬ í‘œì‹œëª…ê³¼ ì¤‘ë³µë˜ëŠ”ì§€ í™•ì¸
                other_display_names = [
                    name for key, name in st.session_state["file_names"].items() if key != original_name
                ]
                if new_display_name in other_display_names:
                    st.warning(f"í‘œì‹œëª… '{new_display_name}'ì´(ê°€) ì´ë¯¸ ë‹¤ë¥¸ íŒŒì¼ì— ì‚¬ìš© ì¤‘ì…ë‹ˆë‹¤.", icon="âš ï¸")
                else:
                    st.session_state["file_names"][original_name] = new_display_name
                    st.rerun() # íŒŒì¼ëª… ë³€ê²½ ì‹œ UI ì¦‰ì‹œ ì—…ë°ì´íŠ¸

        with col_info:
            st.write(f"í–‰ ìˆ˜: {len(df_display)}")
            # ì²« ë²ˆì§¸ ì—´ì˜ UID ê°œìˆ˜ (ì¤‘ë³µ ì œê±°)
            if not df_display.empty and df_display.shape[1] > 0:
                unique_uids = df_display.iloc[:, 0].nunique()
                st.write(f"ê³ ìœ  ID ìˆ˜ (ì²« ì—´): {unique_uids}")
            else:
                st.write("ê³ ìœ  ID ìˆ˜ (ì²« ì—´): ë°ì´í„° ì—†ìŒ")


        with col_download:
            csv_buffer_download = io.StringIO()
            # ë‹¤ìš´ë¡œë“œ ì‹œì—ëŠ” ì›ë³¸ ë°ì´í„°í”„ë ˆì„ì„ ì‚¬ìš©
            st.session_state["csv_dataframes"][original_name].to_csv(csv_buffer_download, index=False, header=False)
            st.download_button(
                label="CSV ë‹¤ìš´ë¡œë“œ",
                data=csv_buffer_download.getvalue(),
                file_name=st.session_state["file_names"].get(original_name, original_name), # í˜„ì¬ í‘œì‹œëª…ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œ
                mime="text/csv",
                key=f"download_btn_individual_{original_name}"
            )

        with col_delete:
            if st.button("íŒŒì¼ ì‚­ì œ", key=f"delete_btn_individual_{original_name}"):
                keys_to_delete_from_session.append(original_name)
    
    if keys_to_delete_from_session:
        for key_del in keys_to_delete_from_session:
            if key_del in st.session_state["csv_dataframes"]:
                del st.session_state["csv_dataframes"][key_del]
            if key_del in st.session_state["file_names"]:
                del st.session_state["file_names"][key_del]
        st.success(f"{len(keys_to_delete_from_session)}ê°œ íŒŒì¼ì´ ì„¸ì…˜ì—ì„œ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.")
        st.rerun() # ì‚­ì œ í›„ UI ê°±ì‹ 

st.markdown("---") # CSV ê´€ë¦¬ ì„¹ì…˜ ë

# ------------------------------------------------------------------------------
# C. ê³µí†µ í•¨ìˆ˜ (CSV ì¡°ì‘ìš©)
# ------------------------------------------------------------------------------
def get_uid_set_from_display_name(display_name):
    """í‘œì‹œ íŒŒì¼ëª…ìœ¼ë¡œ ì›ë³¸ í‚¤ë¥¼ ì°¾ì•„ UID set ìƒì„±"""
    original_key = next((k for k, v in st.session_state["file_names"].items() if v == display_name), None)
    if original_key and original_key in st.session_state["csv_dataframes"]:
        df = st.session_state["csv_dataframes"][original_key]
        if not df.empty and df.shape[1] > 0:
            return set(df.iloc[:, 0].astype(str).dropna().unique()) # NaN ì œê±° ë° ê³ ìœ ê°’
    return set() # íŒŒì¼ì„ ì°¾ì§€ ëª»í•˜ê±°ë‚˜ ë¹„ì–´ìˆìœ¼ë©´ ë¹ˆ set ë°˜í™˜

def save_result_to_session_and_offer_download(result_df, base_filename="result.csv"):
    """ê²°ê³¼ DataFrameì„ ìƒˆ íŒŒì¼ë¡œ ì„¸ì…˜ì— ì¶”ê°€í•˜ê³  ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ ì œê³µ"""
    unique_name_candidate = base_filename
    counter = 1
    # í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ ëª¨ë“  í‘œì‹œ íŒŒì¼ëª… ëª©ë¡
    all_current_display_names = list(st.session_state["file_names"].values())

    # ìƒˆ íŒŒì¼ëª…ì´ ê¸°ì¡´ í‘œì‹œ íŒŒì¼ëª…ê³¼ ì¶©ëŒí•˜ì§€ ì•Šë„ë¡ ì¡°ì •
    while unique_name_candidate in all_current_display_names:
        name_part, ext_part = os.path.splitext(base_filename)
        unique_name_candidate = f"{name_part}_{counter}{ext_part}"
        counter += 1
    
    # ìƒˆ íŒŒì¼ì— ëŒ€í•œ ì›ë³¸ í‚¤ëŠ” í‘œì‹œëª…ê³¼ ë™ì¼í•˜ê²Œ ì‚¬ìš© (ë‹¨ìˆœí™”)
    # ë˜ëŠ” ê³ ìœ  ID (e.g., timestamp)ë¥¼ ìƒì„±í•˜ì—¬ ì‚¬ìš©í•  ìˆ˜ë„ ìˆìŒ
    new_original_key = unique_name_candidate 
    
    st.session_state["csv_dataframes"][new_original_key] = result_df
    st.session_state["file_names"][new_original_key] = unique_name_candidate # í‘œì‹œëª…ë„ ë™ì¼í•˜ê²Œ ì„¤ì •

    csv_buffer_result = io.StringIO()
    result_df.to_csv(csv_buffer_result, index=False, header=False) # UID ëª©ë¡ì´ë¯€ë¡œ í—¤ë” ì—†ì´ ì €ì¥
    
    st.download_button(
        label=f"'{unique_name_candidate}' ë‹¤ìš´ë¡œë“œ ({len(result_df)}ê°œ ID)",
        data=csv_buffer_result.getvalue(),
        file_name=unique_name_candidate,
        mime="text/csv",
        key=f"download_generated_csv_{unique_name_candidate.replace('.', '_')}" # ê³ ìœ  í‚¤
    )
    st.success(f"ê²°ê³¼ íŒŒì¼ '{unique_name_candidate}'ì´(ê°€) ìƒì„±ë˜ì–´ ëª©ë¡ì— ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.")
    st.rerun() # ìƒˆ íŒŒì¼ ëª©ë¡ ì¦‰ì‹œ ë°˜ì˜

# ------------------------------------------------------------------------------
# D. êµì§‘í•© ~ M. ë²¤ ë‹¤ì´ì–´ê·¸ë¨ (ê¸°ì¡´ CSV ê¸°ëŠ¥ë“¤)
# ------------------------------------------------------------------------------
# (ì´ì „ ë‹µë³€ì˜ Dë¶€í„° Mê¹Œì§€ì˜ CSV ì¡°ì‘ ê¸°ëŠ¥ ì½”ë“œë¥¼ ì—¬ê¸°ì— ê·¸ëŒ€ë¡œ ë¶™ì—¬ë„£ìœ¼ì„¸ìš”.)
# ê° st.multiselect, st.selectbox ë“±ì˜ keyê°€ ì¤‘ë³µë˜ì§€ ì•Šë„ë¡ ì£¼ì˜í•˜ì„¸ìš”.
# í•¨ìˆ˜ í˜¸ì¶œ ì‹œ get_uid_set ëŒ€ì‹  get_uid_set_from_display_name ì‚¬ìš©.
# ê²°ê³¼ ì €ì¥ ì‹œ save_to_session_and_download ëŒ€ì‹  save_result_to_session_and_offer_download ì‚¬ìš©.

# ì˜ˆì‹œ: êµì§‘í•© ê¸°ëŠ¥ ìˆ˜ì •
st.header("ğŸ› ï¸ CSV íŒŒì¼ ì¡°í•© ë° ë¶„ì„") # í—¤ë”
st.subheader("2) êµì§‘í•© (Intersection)")
selected_for_intersect = st.multiselect(
    "êµì§‘í•© ëŒ€ìƒ CSV ì„ íƒ (2ê°œ ì´ìƒ)",
    list(st.session_state["file_names"].values()), # í‘œì‹œëª…ìœ¼ë¡œ ì„ íƒ
    key="intersect_select_main"
)
if st.button("êµì§‘í•© ì‹¤í–‰í•˜ê¸°", key="intersect_run_main"):
    if len(selected_for_intersect) < 2:
        st.error("êµì§‘í•©ì€ 2ê°œ ì´ìƒ ì„ íƒí•´ì•¼ í•©ë‹ˆë‹¤.")
    else:
        base_set_intersect = None
        for display_name_intersect in selected_for_intersect:
            current_set_intersect = get_uid_set_from_display_name(display_name_intersect)
            if base_set_intersect is None:
                base_set_intersect = current_set_intersect
            else:
                base_set_intersect.intersection_update(current_set_intersect) # intersection_update ì‚¬ìš©

        if base_set_intersect is not None:
            st.write(f"êµì§‘í•© ê²°ê³¼ UID ìˆ˜: {len(base_set_intersect)}")
            result_df_intersect = pd.DataFrame(sorted(list(base_set_intersect))) # ì •ë ¬ëœ DataFrame
            save_result_to_session_and_offer_download(result_df_intersect, "result_intersection.csv")
        else:
            st.warning("êµì§‘í•©ì„ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤ (ì„ íƒëœ íŒŒì¼ì— ë°ì´í„°ê°€ ì—†ê±°ë‚˜ ë¬¸ì œê°€ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤).")

# (ì—¬ê¸°ì— E.ì¡°í•©, F.Në²ˆì´ìƒ, G.ì¤‘ë³µì œê±°, H.ëœë¤ì¶”ì¶œ, I.ë¹™ê³ , J.ì—´ì‚­ì œ, K.íŒŒì¼ë¶„í• , L.ë§¤íŠ¸ë¦­ìŠ¤, M.ë²¤ë‹¤ì´ì–´ê·¸ë¨ ì½”ë“œ ì‚½ì…)
# ê° ê¸°ëŠ¥ì˜ íŒŒì¼ ì„ íƒ ë¶€ë¶„ì€ list(st.session_state["file_names"].values())ë¥¼ ì‚¬ìš©í•˜ê³ ,
# UID setì„ ê°€ì ¸ì˜¬ ë•ŒëŠ” get_uid_set_from_display_name(ì„ íƒëœ_í‘œì‹œëª…)ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
# ê²°ê³¼ ì €ì¥ ì‹œì—ëŠ” save_result_to_session_and_offer_download(ê²°ê³¼df, "ê¸°ë³¸íŒŒì¼ëª….csv")ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
# ëª¨ë“  st ìœ„ì ¯ì—ëŠ” ê³ ìœ í•œ keyë¥¼ ë¶€ì—¬í•´ì•¼ í•©ë‹ˆë‹¤.

st.markdown("---") # CSV ê¸°ëŠ¥ê³¼ ì›¹íˆ° ì¶”ì¶œ ê¸°ëŠ¥ êµ¬ë¶„

# ------------------------------------------------------------------------------
# N. ì¹´ì¹´ì˜¤í˜ì´ì§€ ì›¹íˆ° ì—…ë°ì´íŠ¸ ì¼ì ì¶”ì¶œ (ì´ì „ ë‹µë³€ì˜ ìµœì¢… ì½”ë“œ ë²„ì „ ì‚¬ìš©)
# ------------------------------------------------------------------------------
# (ì´ì „ ë‹µë³€ì—ì„œ ì œê³µëœ ì¹´ì¹´ì˜¤í˜ì´ì§€ ì›¹íˆ° ì—…ë°ì´íŠ¸ ì¼ì ì¶”ì¶œ ê¸°ëŠ¥ì˜ ìµœì¢… ì½”ë“œë¥¼ ì—¬ê¸°ì— ê·¸ëŒ€ë¡œ ë¶™ì—¬ë„£ìœ¼ì„¸ìš”.)
# st.header, st.text_input, st.button, @st.cache_data ë°ì½”ë ˆì´í„°ê°€ ìˆëŠ” í•¨ìˆ˜,
# get_update_dates_for_series_internal í•¨ìˆ˜, ê·¸ë¦¬ê³  ë©”ì¸ ì‹¤í–‰ ë²„íŠ¼ ë¡œì§ ì „ì²´ì…ë‹ˆë‹¤.
# key ê°’ë“¤ì´ ìœ„ì˜ CSV ê¸°ëŠ¥ë“¤ê³¼ ì¤‘ë³µë˜ì§€ ì•Šë„ë¡ ì£¼ì˜í•˜ì„¸ìš”. (ì˜ˆ: _kp ì ‘ë¯¸ì‚¬ ì¶”ê°€)

st.header("ğŸŒ ì¹´ì¹´ì˜¤í˜ì´ì§€ ì›¹íˆ° ì •ë³´ ì¶”ì¶œ") # í—¤ë”
st.subheader("ì—…ë°ì´íŠ¸ ì¼ì ì¶”ì¶œ")

kakaopage_series_ids_input_kp = st.text_input( # key ë³€ê²½
    "ì¹´ì¹´ì˜¤í˜ì´ì§€ ì‘í’ˆ IDë¥¼ ì‰¼í‘œ(,)ë¡œ êµ¬ë¶„í•˜ì—¬ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: 59782511, 12345678)",
    key="kakaopage_ids_input_main_kp"
)

log_container_kp = st.container()
process_logs_kp = []

# (get_update_dates_for_series_internal í•¨ìˆ˜ëŠ” ì´ì „ ë‹µë³€ì˜ ê²ƒì„ ì—¬ê¸°ì— ë³µì‚¬)
# (get_update_dates_for_series_cached_wrapper í•¨ìˆ˜ëŠ” ì´ì „ ë‹µë³€ì˜ ê²ƒì„ ì—¬ê¸°ì— ë³µì‚¬)
# (ì›¹íˆ° ì¶”ì¶œ ì‹¤í–‰ ë²„íŠ¼ ë¡œì§ì€ ì´ì „ ë‹µë³€ì˜ ê²ƒì„ ì—¬ê¸°ì— ë³µì‚¬, keyëŠ” _kp ë“±ìœ¼ë¡œ ë³€ê²½)

# ì˜ˆì‹œë¡œ get_update_dates_for_series_internal í•¨ìˆ˜ì™€ wrapper, ë²„íŠ¼ ë¡œì§ë§Œ ê°€ì ¸ì˜´
# ì‹¤ì œë¡œëŠ” ì´ í•¨ìˆ˜ë“¤ì„ ì •ì˜í•˜ê³  ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.

# --- ì‹¤ì œ ìŠ¤í¬ë˜í•‘ ë° ìºì‹± í•¨ìˆ˜ (ì´ì „ ë‹µë³€ì˜ ì½”ë“œë¥¼ ì—¬ê¸°ì— ì‚½ì…) ---
def get_update_dates_for_series_internal(series_id, driver, log_callback_ui):
    # ... (ì´ì „ ë‹µë³€ì˜ get_update_dates_for_series_internal í•¨ìˆ˜ ë‚´ìš© ì „ì²´) ...
    # (ì´ í•¨ìˆ˜ëŠ” Streamlit UI ê°ì²´ë¥¼ ì§ì ‘ í˜¸ì¶œí•˜ì§€ ì•Šë„ë¡ log_callback_uië¥¼ ì‚¬ìš©)
    url = f"https://page.kakao.com/content/{series_id}"
    log_callback_ui(f"ID {series_id}: ìŠ¤í¬ë˜í•‘ ì‹œì‘. URL: {url}")
    driver.get(url)
    update_dates = []
    
    try:
        WebDriverWait(driver, 20).until( 
            EC.presence_of_element_located((By.XPATH, "//ul[contains(@class, 'jsx-3287026398')]"))
        )
        log_callback_ui(f"ID {series_id}: ì´ˆê¸° íšŒì°¨ ëª©ë¡ ì»¨í…Œì´ë„ˆ(ul) ë¡œë“œ í™•ì¸.")
        time.sleep(3) 

        max_scroll_attempts = 25 
        no_new_content_streak = 0
        max_no_new_content_streak = 3
        
        initial_items_count = len(driver.find_elements(By.XPATH, "//ul[contains(@class, 'jsx-3287026398')]/li"))
        log_callback_ui(f"ID {series_id}: 'ë”ë³´ê¸°' ì „, ì´ˆê¸° ê°ì§€ëœ íšŒì°¨ ì•„ì´í…œ ìˆ˜: {initial_items_count}")

        for attempt in range(max_scroll_attempts):
            items_before_click_elements = driver.find_elements(By.XPATH, "//ul[contains(@class, 'jsx-3287026398')]/li//div[contains(@class, 'font-x-small1')]//span[@class='break-all align-middle'][1]")
            count_before_click = len(items_before_click_elements)

            try:
                load_more_button_xpath = "//ul[contains(@class, 'jsx-3287026398')]/following-sibling::div[1][.//img[@alt='ì•„ë˜ í™”ì‚´í‘œ']]"
                load_more_button = WebDriverWait(driver, 8).until( 
                    EC.element_to_be_clickable((By.XPATH, load_more_button_xpath))
                )
                driver.execute_script("arguments[0].scrollIntoView({block: 'center', inline: 'nearest'});", load_more_button)
                time.sleep(0.6) 
                driver.execute_script("arguments[0].click();", load_more_button)
                log_callback_ui(f"ID {series_id}: 'ë”ë³´ê¸°' ë²„íŠ¼ í´ë¦­ ({attempt + 1}/{max_scroll_attempts}).")
                time.sleep(2) 

                items_after_click_elements = driver.find_elements(By.XPATH, "//ul[contains(@class, 'jsx-3287026398')]/li//div[contains(@class, 'font-x-small1')]//span[@class='break-all align-middle'][1]")
                count_after_click = len(items_after_click_elements)

                if count_after_click == count_before_click:
                    no_new_content_streak += 1
                    log_callback_ui(f"ID {series_id}: ìƒˆ ì½˜í…ì¸  ë³€í™” ì—†ìŒ ({no_new_content_streak}/{max_no_new_content_streak}). í˜„ì¬ê¹Œì§€ ê°ì§€ëœ ë‚ ì§œ ìˆ˜: {count_after_click}.")
                    if no_new_content_streak >= max_no_new_content_streak:
                        log_callback_ui(f"ID {series_id}: ì—°ì† {max_no_new_content_streak}íšŒ ìƒˆ ì½˜í…ì¸  ë³€í™” ì—†ì–´ 'ë”ë³´ê¸°' ì¤‘ë‹¨.")
                        break
                else:
                    no_new_content_streak = 0
                    log_callback_ui(f"ID {series_id}: ìƒˆ ì½˜í…ì¸  ë¡œë“œë¨. í˜„ì¬ê¹Œì§€ ê°ì§€ëœ ë‚ ì§œ ìˆ˜: {count_after_click}.")
            
            except TimeoutException:
                log_callback_ui(f"ID {series_id}: 'ë”ë³´ê¸°' ë²„íŠ¼ íƒ€ì„ì•„ì›ƒ. ëª¨ë“  íšŒì°¨ ë¡œë“œ ì™„ë£Œë¡œ ê°„ì£¼.")
                break
            except NoSuchElementException:
                log_callback_ui(f"ID {series_id}: 'ë”ë³´ê¸°' ë²„íŠ¼ì„ ë” ì´ìƒ ì°¾ì„ ìˆ˜ ì—†ìŒ. ëª¨ë“  íšŒì°¨ ë¡œë“œ ì™„ë£Œë¡œ ê°„ì£¼.")
                break
            except ElementClickInterceptedException:
                log_callback_ui(f"ID {series_id}: 'ë”ë³´ê¸°' ë²„íŠ¼ í´ë¦­ ê°€ë¡œì±„ì§. í˜ì´ì§€ í•˜ë‹¨ìœ¼ë¡œ ìŠ¤í¬ë¡¤ í›„ ì¬ì‹œë„.")
                driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
                time.sleep(1.5) 
            except Exception as e_click_internal_error:
                log_callback_ui(f"ID {series_id}: 'ë”ë³´ê¸°' ë²„íŠ¼ í´ë¦­ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {str(e_click_internal_error)[:100]}")
                break

        episode_list_items_xpath = "//ul[contains(@class, 'jsx-3287026398')]/li[contains(@class, 'list-child-item')]"
        list_items_elements = driver.find_elements(By.XPATH, episode_list_items_xpath)
        log_callback_ui(f"ID {series_id}: ìµœì¢…ì ìœ¼ë¡œ ìŠ¤ìº”í•  íšŒì°¨ ì•„ì´í…œ ìš”ì†Œ ìˆ˜: {len(list_items_elements)}.")
        if not list_items_elements:
            log_callback_ui(f"ID {series_id}: [ê²½ê³ ] ìµœì¢… íšŒì°¨ ì•„ì´í…œ ìš”ì†Œë¥¼ í•˜ë‚˜ë„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

        date_pattern = re.compile(r"^\d{2}\.\d{2}\.\d{2}$")
        extracted_this_run = []
        for idx, item_element in enumerate(list_items_elements):
            try:
                date_span_xpath = ".//div[contains(@class, 'font-x-small1') and contains(@class, 'h-16pxr') and contains(@class, 'text-el-50')]/span[@class='break-all align-middle'][1]"
                date_span = item_element.find_element(By.XPATH, date_span_xpath)
                date_text = date_span.text.strip()
                if date_pattern.match(date_text):
                    extracted_this_run.append(date_text)
            except NoSuchElementException:
                pass 
            except Exception: 
                pass
        
        seen_dates = set()
        for d_item_internal in extracted_this_run:
            if d_item_internal not in seen_dates:
                update_dates.append(d_item_internal)
                seen_dates.add(d_item_internal)
        
        if not update_dates:
            log_callback_ui(f"ID {series_id}: [ê²°ê³¼] ì¶”ì¶œëœ ì—…ë°ì´íŠ¸ ë‚ ì§œê°€ ì—†ìŠµë‹ˆë‹¤. (ì´ {len(extracted_this_run)}ê°œì˜ ë‚ ì§œ í˜•ì‹ í…ìŠ¤íŠ¸ ì¤‘ ìœ íš¨í•œ ë‚ ì§œ 0ê°œ)")
        else:
            log_callback_ui(f"ID {series_id}: [ê²°ê³¼] {len(update_dates)}ê°œì˜ ê³ ìœ í•œ ì—…ë°ì´íŠ¸ ë‚ ì§œ ì¶”ì¶œ ì™„ë£Œ.")
                
    except TimeoutException:
        log_callback_ui(f"ID {series_id}: [ì˜¤ë¥˜] í˜ì´ì§€ì˜ ì£¼ìš” ì»¨í…ì¸ (íšŒì°¨ ëª©ë¡) ë¡œë“œ ì‹œê°„ ì´ˆê³¼.")
    except Exception as e_global_scrape_internal_error:
        log_callback_ui(f"ID {series_id}: [ì˜¤ë¥˜] ìŠ¤í¬ë˜í•‘ ì¤‘ ì˜ˆê¸°ì¹˜ ì•Šì€ ì˜¤ë¥˜ ë°œìƒ: {str(e_global_scrape_internal_error)[:150]}")
    
    return update_dates

@st.cache_data(ttl=3600, show_spinner=False)
def get_update_dates_for_series_cached_wrapper(series_id, webdriver_options_dict):
    temp_logs_for_cache = []
    def append_log_for_cache_internal(message):
        temp_logs_for_cache.append(message)

    options = webdriver.ChromeOptions()
    for arg_name, arg_val in webdriver_options_dict.get("arguments", {}).items():
        if arg_val is None: options.add_argument(arg_name)
        else: options.add_argument(f"{arg_name}={arg_val}")
    for opt_name, opt_value in webdriver_options_dict.get("experimental_options", {}).items():
        options.add_experimental_option(opt_name, opt_value)

    driver_instance_cache_internal = None
    try:
        s_cache_internal = ChromeService(ChromeDriverManager().install())
        driver_instance_cache_internal = webdriver.Chrome(service=s_cache_internal, options=options)
        dates = get_update_dates_for_series_internal(series_id, driver_instance_cache_internal, append_log_for_cache_internal)
        return dates, temp_logs_for_cache
    except Exception as e_cache_internal:
        append_log_for_cache_internal(f"ID {series_id}: ìºì‹œëœ WebDriver ì‹¤í–‰ ì¤‘ ì‹¬ê°í•œ ì˜¤ë¥˜: {str(e_cache_internal)}")
        return [], temp_logs_for_cache
    finally:
        if driver_instance_cache_internal:
            driver_instance_cache_internal.quit()

if st.button("ì—…ë°ì´íŠ¸ ì¼ì ì¶”ì¶œ ë° ZIP ë‹¤ìš´ë¡œë“œ", key="kakaopage_extract_button_main_kp"): # key ë³€ê²½
    if not kakaopage_series_ids_input_kp:
        st.warning("ì‘í’ˆ IDë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    else:
        series_ids_list_kp = [id_str.strip() for id_str in kakaopage_series_ids_input_kp.split(',') if id_str.strip()]
        if not series_ids_list_kp:
            st.warning("ìœ íš¨í•œ ì‘í’ˆ IDê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            webdriver_options_dict_for_cache_final_kp = {
                "arguments": {
                    "--headless": None, "--no-sandbox": None, "--disable-dev-shm-usage": None,
                    "--disable-gpu": None,
                    "user-agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/114.0.0.0 Safari/537.36",
                    "--lang": "ko_KR", "--window-size=1920,1080"
                },
                "experimental_options": {"excludeSwitches": ['enable-logging']}
            }
            
            results_for_zip_kp = {}
            total_ids_kp = len(series_ids_list_kp)
            
            process_logs_kp.clear()
            log_container_kp.empty()
            log_display_area_kp = log_container_kp.expander("ì‹¤ì‹œê°„ ì²˜ë¦¬ ë¡œê·¸ ë³´ê¸°", expanded=True)
            
            progress_bar_placeholder_kp = st.empty()
            current_status_text_kp = st.empty()
            overall_start_time_kp = time.time()

            with st.spinner(f"ì´ {total_ids_kp}ê°œì˜ ì‘í’ˆ ì •ë³´ë¥¼ ì²˜ë¦¬ ì¤‘ì…ë‹ˆë‹¤... (ê° ID ì²˜ë¦¬ ì‹œ ì›¹í˜ì´ì§€ë¥¼ ì§ì ‘ ë°©ë¬¸í•©ë‹ˆë‹¤)"):
                progress_bar_kp = progress_bar_placeholder_kp.progress(0)
                
                for i, series_id_item_kp in enumerate(series_ids_list_kp):
                    start_time_item_kp = time.time()
                    current_progress_kp = (i + 1) / total_ids_kp
                    progress_bar_kp.progress(current_progress_kp)
                    current_status_text_kp.text(f"ì²˜ë¦¬ ì¤‘: {series_id_item_kp} ({i+1}/{total_ids_kp})")
                    
                    process_logs_kp.append(f"--- ID: {series_id_item_kp} ì²˜ë¦¬ ì‹œì‘ ---")
                    with log_display_area_kp: st.markdown(f"**ID: {series_id_item_kp} ì²˜ë¦¬ ì‹œì‘...**")
                    
                    dates_kp, item_logs_from_cache_kp = get_update_dates_for_series_cached_wrapper(series_id_item_kp, webdriver_options_dict_for_cache_final_kp)
                    
                    process_logs_kp.extend(item_logs_from_cache_kp)
                    with log_display_area_kp:
                        for log_msg_kp in item_logs_from_cache_kp:
                            if "[ì˜¤ë¥˜]" in log_msg_kp or "[ê²½ê³ ]" in log_msg_kp: st.warning(log_msg_kp)
                            else: st.info(log_msg_kp)
                    
                    if dates_kp:
                        file_content_kp = "\n".join(dates_kp)
                        safe_series_id_kp = re.sub(r'[\\/*?:"<>|]', "_", series_id_item_kp)
                        filename_in_zip_kp = f"{safe_series_id_kp}_updates.txt"
                        results_for_zip_kp[filename_in_zip_kp] = file_content_kp
                        final_msg_kp = f"ID {series_id_item_kp}: [ì„±ê³µ] {len(dates_kp)}ê°œ ì—…ë°ì´íŠ¸ ì¼ì ì¶”ì¶œ ì™„ë£Œ."
                        process_logs_kp.append(final_msg_kp)
                        with log_display_area_kp: st.success(final_msg_kp)
                    else:
                        final_msg_kp = f"ID {series_id_item_kp}: [ì‹¤íŒ¨] ì—…ë°ì´íŠ¸ ì¼ìë¥¼ ì°¾ì„ ìˆ˜ ì—†ê±°ë‚˜ ì¶”ì¶œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
                        process_logs_kp.append(final_msg_kp)
                        with log_display_area_kp: st.error(final_msg_kp)
                    
                    end_time_item_kp = time.time()
                    process_logs_kp.append(f"ID {series_id_item_kp} ì²˜ë¦¬ ì†Œìš” ì‹œê°„: {end_time_item_kp - start_time_item_kp:.2f}ì´ˆ")
                    process_logs_kp.append(f"--- ID: {series_id_item_kp} ì²˜ë¦¬ ì¢…ë£Œ ---\n")
                    with log_display_area_kp: st.markdown("---")
                    time.sleep(0.3)

            progress_bar_placeholder_kp.empty()
            current_status_text_kp.empty()
            overall_end_time_kp = time.time()
            process_logs_kp.insert(0, f"**ì¹´ì¹´ì˜¤í˜ì´ì§€ ì¶”ì¶œ ì „ì²´ ì‘ì—… ì™„ë£Œ! ì´ ì†Œìš” ì‹œê°„: {overall_end_time_kp - overall_start_time_kp:.2f}ì´ˆ**")

            if results_for_zip_kp:
                log_final_summary_kp = "ëª¨ë“  ì‘í’ˆ ì²˜ë¦¬ ì™„ë£Œ. ZIP íŒŒì¼ ìƒì„± ì¤‘..."
                process_logs_kp.append(log_final_summary_kp)
                # st.info(log_final_summary_kp) # expanderì— í‘œì‹œë˜ë¯€ë¡œ ì¤‘ë³µ ì œê±°

                zip_buffer_kp = io.BytesIO()
                with zipfile.ZipFile(zip_buffer_kp, "w", zipfile.ZIP_DEFLATED) as zf_kp:
                    for filename_kp, content_kp in results_for_zip_kp.items():
                        zf_kp.writestr(filename_kp, content_kp.encode('utf-8'))
                zip_buffer_kp.seek(0)
                
                st.download_button(
                    label="ì¶”ì¶œëœ ì—…ë°ì´íŠ¸ ì¼ì ZIP ë‹¤ìš´ë¡œë“œ",
                    data=zip_buffer_kp,
                    file_name="kakaopage_webtoon_updates.zip",
                    mime="application/zip",
                    key="download_kakaopage_zip_main_v3"
                )
                process_logs_kp.append("ZIP íŒŒì¼ ìƒì„± ì™„ë£Œ! ìœ„ ë²„íŠ¼ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œí•˜ì„¸ìš”.")
                st.success("ì¹´ì¹´ì˜¤í˜ì´ì§€ ì—…ë°ì´íŠ¸ ì¼ì ZIP íŒŒì¼ ìƒì„± ì™„ë£Œ! ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ì„ ì´ìš©í•˜ì„¸ìš”.")
            else:
                log_final_summary_kp = "ì¶”ì¶œëœ ë°ì´í„°ê°€ ì—†ì–´ ZIP íŒŒì¼ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                process_logs_kp.append(log_final_summary_kp)
                st.warning(log_final_summary_kp)
            
            log_container_kp.empty()
            with st.expander("ì¹´ì¹´ì˜¤í˜ì´ì§€ ì¶”ì¶œ ì „ì²´ ìƒì„¸ ì²˜ë¦¬ ë¡œê·¸ ë³´ê¸°", expanded=False):
                for log_line_kp in process_logs_kp:
                    if "ID:" in log_line_kp and "ì‹œì‘" in log_line_kp: st.markdown(f"**{log_line_kp}**")
                    elif "[ì„±ê³µ]" in log_line_kp: st.success(log_line_kp)
                    elif "[ì‹¤íŒ¨]" in log_line_kp or "[ì˜¤ë¥˜]" in log_line_kp or "[ê²½ê³ ]" in log_line_kp : st.error(log_line_kp)
                    elif "ì†Œìš” ì‹œê°„" in log_line_kp or "ì²˜ë¦¬ ì¢…ë£Œ" in log_line_kp: st.caption(log_line_kp)
                    elif "ZIP íŒŒì¼" in log_line_kp or "ì´ ì†Œìš” ì‹œê°„" in log_line_kp: st.info(log_line_kp)
                    else: st.markdown(f"`{log_line_kp}`")
# ------------------------------------------------------------------------------
# ì•± í•˜ë‹¨ ì •ë³´ (ì„ íƒ ì‚¬í•­)
# ------------------------------------------------------------------------------
st.markdown("---")
st.caption("Pinsight Utility App by YourName/Organization (ë¬¸ì˜: ...)")
