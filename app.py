import math
import streamlit as st
import pandas as pd
import io
import zipfile
from collections import defaultdict
import time
import matplotlib.pyplot as plt
from matplotlib.patches import Rectangle
from matplotlib_venn import venn2, venn3, venn2_circles, venn3_circles # ë²¤ë‹¤ì´ì–´ê·¸ë¨ ì‚¬ìš© ì‹œ (í•„ìš”ì‹œ ì„¤ì¹˜)

# Selenium ê´€ë ¨ import
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, NoSuchElementException, ElementClickInterceptedException
from selenium.webdriver.chrome.service import Service as ChromeService
from webdriver_manager.chrome import ChromeDriverManager
import re
import os # íŒŒì¼ëª… ì²˜ë¦¬ ë“±

st.set_page_config(page_title="Pinsight CSV & Webtoon Utility", layout="wide") # ì•± ì œëª© ë³€ê²½
st.title("Pinsight CSV & ì›¹íˆ° ì •ë³´ ì¶”ì¶œ ë„êµ¬") # ì•± ì œëª© ë³€ê²½

# ------------------------------------------------------------------------------
# A. CSV ì—…ë¡œë“œ ì²˜ë¦¬
# ------------------------------------------------------------------------------
st.header("ğŸ“„ CSV íŒŒì¼ ê´€ë¦¬") # í—¤ë”ë¡œ ë³€ê²½
st.subheader("1) CSV ì—…ë¡œë“œ")

uploaded_files = st.file_uploader(
    "ì—¬ê¸°ì— CSV íŒŒì¼ë“¤ì„ ë“œë˜ê·¸í•˜ê±°ë‚˜, 'Browse files' ë²„íŠ¼ì„ ëˆŒëŸ¬ ì„ íƒí•˜ì„¸ìš”. (ê° CSVëŠ” ì²« ë²ˆì§¸ ì—´ì— IDê°€ ìˆì–´ì•¼ í•©ë‹ˆë‹¤)",
    type=["csv"],
    accept_multiple_files=True
)

# ì„¸ì…˜ ìƒíƒœ ì´ˆê¸°í™” (ì•± ì‹¤í–‰ ì‹œ í•œ ë²ˆë§Œ)
if "csv_dataframes" not in st.session_state:
    st.session_state["csv_dataframes"] = {}
if "file_names" not in st.session_state:
    st.session_state["file_names"] = {}

if st.button("CSV ë¡œë“œí•˜ê¸°", key="load_csv_button"):
    if uploaded_files:
        loaded_count = 0
        for uploaded_file in uploaded_files:
            # ì´ë¯¸ ë¡œë“œëœ íŒŒì¼ëª…ì¸ì§€ í™•ì¸ (ë®ì–´ì“°ê¸° ë°©ì§€ ë˜ëŠ” ì‚¬ìš©ìì—ê²Œ ì•Œë¦¼)
            if uploaded_file.name in st.session_state["csv_dataframes"]:
                st.warning(f"'{uploaded_file.name}' íŒŒì¼ì€ ì´ë¯¸ ë¡œë“œë˜ì–´ ìˆìŠµë‹ˆë‹¤. ìƒˆë¡œ ë¡œë“œí•˜ë ¤ë©´ ê¸°ì¡´ íŒŒì¼ì„ ì‚­ì œ í›„ ì§„í–‰í•´ì£¼ì„¸ìš”.", icon="âš ï¸")
                continue # ë‹¤ìŒ íŒŒì¼ë¡œ ë„˜ì–´ê°

            try:
                # CSVë¥¼ ì½ì„ ë•Œ, ì²« ë²ˆì§¸ ì—´ë§Œ ì‚¬ìš©í•˜ê³  ë‚˜ë¨¸ì§€ëŠ” ë¬´ì‹œí•˜ê±°ë‚˜, í•„ìš”ì— ë”°ë¼ ì²˜ë¦¬
                # ì—¬ê¸°ì„œëŠ” ëª¨ë“  ì—´ì„ ì½ë˜, UIDëŠ” ì²« ë²ˆì§¸ ì—´ë¡œ ê°€ì •
                df = pd.read_csv(uploaded_file, header=None, dtype=str) # ëª¨ë“  ë°ì´í„°ë¥¼ ë¬¸ìì—´ë¡œ ì½ê¸° (UID ì¼ê´€ì„±)
                if df.empty or df.shape[1] == 0:
                    st.error(f"'{uploaded_file.name}' íŒŒì¼ì´ ë¹„ì–´ìˆê±°ë‚˜ ìœ íš¨í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                    continue

                st.session_state["csv_dataframes"][uploaded_file.name] = df
                st.session_state["file_names"][uploaded_file.name] = uploaded_file.name # ì´ˆê¸° íŒŒì¼ëª… ì„¤ì •
                st.success(f"'{uploaded_file.name}': ì—…ë¡œë“œ & ë¡œë“œ ì„±ê³µ (í–‰ ìˆ˜: {len(df)})")
                loaded_count +=1
            except pd.errors.EmptyDataError:
                st.error(f"'{uploaded_file.name}': íŒŒì¼ì´ ë¹„ì–´ìˆì–´ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            except Exception as e:
                st.error(f"'{uploaded_file.name}': ë¡œë“œ ì‹¤íŒ¨ - {e}")
        if loaded_count > 0 :
            st.rerun() # íŒŒì¼ ëª©ë¡ ì¦‰ì‹œ ì—…ë°ì´íŠ¸
    else:
        st.warning("ì—…ë¡œë“œëœ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")

# ------------------------------------------------------------------------------
# B. ì—…ë¡œë“œëœ íŒŒì¼ ëª©ë¡ í‘œì‹œ (íŒŒì¼ëª… ë³€ê²½ ë° ì‚­ì œ ê¸°ëŠ¥)
# ------------------------------------------------------------------------------
if st.session_state["csv_dataframes"]:
    st.write("### ì—…ë¡œë“œëœ íŒŒì¼ ëª©ë¡ ë° ê´€ë¦¬")
    
    # ì‚­ì œí•  íŒŒì¼ í‚¤ë¥¼ ì„ì‹œ ì €ì¥ (ìˆœíšŒ ì¤‘ ë”•ì…”ì…”ë„ˆë¦¬ ë³€ê²½ ë°©ì§€)
    keys_to_delete_from_session = []

    for original_name in list(st.session_state["csv_dataframes"].keys()): # ìˆœíšŒ ì¤‘ ë³€ê²½ ë°©ì§€
        if original_name not in st.session_state["csv_dataframes"]: continue # ì´ë¯¸ ì‚­ì œëœ ê²½ìš°

        df_display = st.session_state["csv_dataframes"][original_name]
        
        col_name, col_info, col_download, col_delete = st.columns([3, 2, 1.5, 1])

        with col_name:
            # íŒŒì¼ëª… ë³€ê²½ ì…ë ¥ í•„ë“œ
            current_display_name = st.session_state["file_names"].get(original_name, original_name)
            new_display_name = st.text_input(
                f"íŒŒì¼ëª… (ì›ë³¸: {original_name})",
                value=current_display_name,
                key=f"text_input_filename_{original_name}"
            )
            if new_display_name != current_display_name:
                # ìƒˆ íŒŒì¼ëª…ì´ ë‹¤ë¥¸ íŒŒì¼ì˜ í˜„ì¬ í‘œì‹œëª…ê³¼ ì¤‘ë³µë˜ëŠ”ì§€ í™•ì¸
                other_display_names = [
                    name for key, name in st.session_state["file_names"].items() if key != original_name
                ]
                if new_display_name in other_display_names:
                    st.warning(f"í‘œì‹œëª… '{new_display_name}'ì´(ê°€) ì´ë¯¸ ë‹¤ë¥¸ íŒŒì¼ì— ì‚¬ìš© ì¤‘ì…ë‹ˆë‹¤.", icon="âš ï¸")
                else:
                    st.session_state["file_names"][original_name] = new_display_name
                    st.rerun() # íŒŒì¼ëª… ë³€ê²½ ì‹œ UI ì¦‰ì‹œ ì—…ë°ì´íŠ¸

        with col_info:
            st.write(f"í–‰ ìˆ˜: {len(df_display)}")
            # ì²« ë²ˆì§¸ ì—´ì˜ UID ê°œìˆ˜ (ì¤‘ë³µ ì œê±°)
            if not df_display.empty and df_display.shape[1] > 0:
                unique_uids = df_display.iloc[:, 0].nunique()
                st.write(f"ê³ ìœ  ID ìˆ˜ (ì²« ì—´): {unique_uids}")
            else:
                st.write("ê³ ìœ  ID ìˆ˜ (ì²« ì—´): ë°ì´í„° ì—†ìŒ")


        with col_download:
            csv_buffer_download = io.StringIO()
            # ë‹¤ìš´ë¡œë“œ ì‹œì—ëŠ” ì›ë³¸ ë°ì´í„°í”„ë ˆì„ì„ ì‚¬ìš©
            st.session_state["csv_dataframes"][original_name].to_csv(csv_buffer_download, index=False, header=False)
            st.download_button(
                label="CSV ë‹¤ìš´ë¡œë“œ",
                data=csv_buffer_download.getvalue(),
                file_name=st.session_state["file_names"].get(original_name, original_name), # í˜„ì¬ í‘œì‹œëª…ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œ
                mime="text/csv",
                key=f"download_btn_individual_{original_name}"
            )

        with col_delete:
            if st.button("íŒŒì¼ ì‚­ì œ", key=f"delete_btn_individual_{original_name}"):
                keys_to_delete_from_session.append(original_name)
    
    if keys_to_delete_from_session:
        for key_del in keys_to_delete_from_session:
            if key_del in st.session_state["csv_dataframes"]:
                del st.session_state["csv_dataframes"][key_del]
            if key_del in st.session_state["file_names"]:
                del st.session_state["file_names"][key_del]
        st.success(f"{len(keys_to_delete_from_session)}ê°œ íŒŒì¼ì´ ì„¸ì…˜ì—ì„œ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.")
        st.rerun() # ì‚­ì œ í›„ UI ê°±ì‹ 

st.markdown("---") # CSV ê´€ë¦¬ ì„¹ì…˜ ë

# ------------------------------------------------------------------------------
# C. ê³µí†µ í•¨ìˆ˜ (CSV ì¡°ì‘ìš©)
# ------------------------------------------------------------------------------
def get_uid_set_from_display_name(display_name):
    """í‘œì‹œ íŒŒì¼ëª…ìœ¼ë¡œ ì›ë³¸ í‚¤ë¥¼ ì°¾ì•„ UID set ìƒì„±"""
    original_key = next((k for k, v in st.session_state["file_names"].items() if v == display_name), None)
    if original_key and original_key in st.session_state["csv_dataframes"]:
        df = st.session_state["csv_dataframes"][original_key]
        if not df.empty and df.shape[1] > 0:
            return set(df.iloc[:, 0].astype(str).dropna().unique()) # NaN ì œê±° ë° ê³ ìœ ê°’
    return set() # íŒŒì¼ì„ ì°¾ì§€ ëª»í•˜ê±°ë‚˜ ë¹„ì–´ìˆìœ¼ë©´ ë¹ˆ set ë°˜í™˜

def save_result_to_session_and_offer_download(result_df, base_filename="result.csv"):
    """ê²°ê³¼ DataFrameì„ ìƒˆ íŒŒì¼ë¡œ ì„¸ì…˜ì— ì¶”ê°€í•˜ê³  ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ ì œê³µ"""
    unique_name_candidate = base_filename
    counter = 1
    # í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ ëª¨ë“  í‘œì‹œ íŒŒì¼ëª… ëª©ë¡
    all_current_display_names = list(st.session_state["file_names"].values())

    # ìƒˆ íŒŒì¼ëª…ì´ ê¸°ì¡´ í‘œì‹œ íŒŒì¼ëª…ê³¼ ì¶©ëŒí•˜ì§€ ì•Šë„ë¡ ì¡°ì •
    while unique_name_candidate in all_current_display_names:
        name_part, ext_part = os.path.splitext(base_filename)
        unique_name_candidate = f"{name_part}_{counter}{ext_part}"
        counter += 1
    
    # ìƒˆ íŒŒì¼ì— ëŒ€í•œ ì›ë³¸ í‚¤ëŠ” í‘œì‹œëª…ê³¼ ë™ì¼í•˜ê²Œ ì‚¬ìš© (ë‹¨ìˆœí™”)
    # ë˜ëŠ” ê³ ìœ  ID (e.g., timestamp)ë¥¼ ìƒì„±í•˜ì—¬ ì‚¬ìš©í•  ìˆ˜ë„ ìˆìŒ
    new_original_key = unique_name_candidate 
    
    st.session_state["csv_dataframes"][new_original_key] = result_df
    st.session_state["file_names"][new_original_key] = unique_name_candidate # í‘œì‹œëª…ë„ ë™ì¼í•˜ê²Œ ì„¤ì •

    csv_buffer_result = io.StringIO()
    result_df.to_csv(csv_buffer_result, index=False, header=False) # UID ëª©ë¡ì´ë¯€ë¡œ í—¤ë” ì—†ì´ ì €ì¥
    
    st.download_button(
        label=f"'{unique_name_candidate}' ë‹¤ìš´ë¡œë“œ ({len(result_df)}ê°œ ID)",
        data=csv_buffer_result.getvalue(),
        file_name=unique_name_candidate,
        mime="text/csv",
        key=f"download_generated_csv_{unique_name_candidate.replace('.', '_')}" # ê³ ìœ  í‚¤
    )
    st.success(f"ê²°ê³¼ íŒŒì¼ '{unique_name_candidate}'ì´(ê°€) ìƒì„±ë˜ì–´ ëª©ë¡ì— ì¶”ê°€ë˜ì—ˆìŠµë‹ˆë‹¤.")
    st.rerun() # ìƒˆ íŒŒì¼ ëª©ë¡ ì¦‰ì‹œ ë°˜ì˜

# ------------------------------------------------------------------------------
# D. êµì§‘í•© ~ M. ë²¤ ë‹¤ì´ì–´ê·¸ë¨ (ê¸°ì¡´ CSV ê¸°ëŠ¥ë“¤)
# ------------------------------------------------------------------------------
# (ì´ì „ ë‹µë³€ì˜ Dë¶€í„° Mê¹Œì§€ì˜ CSV ì¡°ì‘ ê¸°ëŠ¥ ì½”ë“œë¥¼ ì—¬ê¸°ì— ê·¸ëŒ€ë¡œ ë¶™ì—¬ë„£ìœ¼ì„¸ìš”.)
# ê° st.multiselect, st.selectbox ë“±ì˜ keyê°€ ì¤‘ë³µë˜ì§€ ì•Šë„ë¡ ì£¼ì˜í•˜ì„¸ìš”.
# í•¨ìˆ˜ í˜¸ì¶œ ì‹œ get_uid_set ëŒ€ì‹  get_uid_set_from_display_name ì‚¬ìš©.
# ê²°ê³¼ ì €ì¥ ì‹œ save_to_session_and_download ëŒ€ì‹  save_result_to_session_and_offer_download ì‚¬ìš©.

# ì˜ˆì‹œ: êµì§‘í•© ê¸°ëŠ¥ ìˆ˜ì •
st.header("ğŸ› ï¸ CSV íŒŒì¼ ì¡°í•© ë° ë¶„ì„") # í—¤ë”
st.subheader("2) êµì§‘í•© (Intersection)")
selected_for_intersect = st.multiselect(
    "êµì§‘í•© ëŒ€ìƒ CSV ì„ íƒ (2ê°œ ì´ìƒ)",
    list(st.session_state["file_names"].values()), # í‘œì‹œëª…ìœ¼ë¡œ ì„ íƒ
    key="intersect_select_main"
)
if st.button("êµì§‘í•© ì‹¤í–‰í•˜ê¸°", key="intersect_run_main"):
    if len(selected_for_intersect) < 2:
        st.error("êµì§‘í•©ì€ 2ê°œ ì´ìƒ ì„ íƒí•´ì•¼ í•©ë‹ˆë‹¤.")
    else:
        base_set_intersect = None
        for display_name_intersect in selected_for_intersect:
            current_set_intersect = get_uid_set_from_display_name(display_name_intersect)
            if base_set_intersect is None:
                base_set_intersect = current_set_intersect
            else:
                base_set_intersect.intersection_update(current_set_intersect) # intersection_update ì‚¬ìš©

        if base_set_intersect is not None:
            st.write(f"êµì§‘í•© ê²°ê³¼ UID ìˆ˜: {len(base_set_intersect)}")
            result_df_intersect = pd.DataFrame(sorted(list(base_set_intersect))) # ì •ë ¬ëœ DataFrame
            save_result_to_session_and_offer_download(result_df_intersect, "result_intersection.csv")
        else:
            st.warning("êµì§‘í•©ì„ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤ (ì„ íƒëœ íŒŒì¼ì— ë°ì´í„°ê°€ ì—†ê±°ë‚˜ ë¬¸ì œê°€ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤).")

# ------------------------------------------------------------------------------
# E. ì¡°í•© (í•©ì§‘í•© + ì œì™¸)
# ------------------------------------------------------------------------------
st.subheader("3) ì¡°í•©í•˜ê¸° (í¬í•¨/ì œì™¸)")
col1_comb, col2_comb = st.columns(2)
with col1_comb:
    plus_list = st.multiselect("í¬í•¨(+)í•  CSVë“¤", list(st.session_state["file_names"].values()), key="comb_plus")
with col2_comb:
    minus_list = st.multiselect("ì œì™¸(-)í•  CSVë“¤", list(st.session_state["file_names"].values()), key="comb_minus")
if st.button("ì¡°í•©í•˜ê¸° ì‹¤í–‰", key="comb_run"):
    if not plus_list:
        st.error("ìµœì†Œ 1ê°œ ì´ìƒ 'í¬í•¨' ë¦¬ìŠ¤íŠ¸ë¥¼ ì§€ì •í•´ì•¼ í•©ë‹ˆë‹¤.")
    else:
        plus_set = set()
        for p in plus_list:
            orig_key = [k for k, v in st.session_state["file_names"].items() if v == p][0]
            plus_set = plus_set.union(get_uid_set(orig_key))
        minus_set = set()
        for m in minus_list:
            orig_key = [k for k, v in st.session_state["file_names"].items() if v == p][0] # ë²„ê·¸ ìˆ˜ì •: p -> m
            minus_set = minus_set.union(get_uid_set(orig_key))
        final = plus_set - minus_set
        st.write(f"ì¡°í•© ê²°ê³¼ UID ìˆ˜: {len(final)}")
        result_df = pd.DataFrame(sorted(list(final)))
        save_to_session_and_download(result_df, "result_combination.csv")


# ------------------------------------------------------------------------------
# F. Në²ˆ ì´ìƒ ë˜ëŠ” ì •í™•íˆ Në²ˆ CSVì—ì„œ ë“±ì¥í•˜ëŠ” UID ì¶”ì¶œ
# ------------------------------------------------------------------------------
st.subheader("4) Në²ˆ ì´ìƒ / ì •í™•íˆ Në²ˆ ë“±ì¥í•˜ëŠ” UID ì¶”ì¶œ")
selected_for_nplus = st.multiselect(
    "ëŒ€ìƒ CSV ì„ íƒ (1ê°œ ì´ìƒ)",
    list(st.session_state["file_names"].values()),
    key="nplus_select"
)
threshold = st.number_input(
    "ëª‡ ê°œì˜ CSV íŒŒì¼ì—ì„œ ë“±ì¥í•˜ëŠ” UIDë¥¼ ì°¾ì„ê¹Œìš”?",
    min_value=1, value=2, step=1, key="nplus_threshold"
)
condition_option = st.radio(
    "ì¶”ì¶œ ì¡°ê±´ ì„ íƒ",
    ("Në²ˆ ì´ìƒ ë“±ì¥", "ì •í™•íˆ Në²ˆ ë“±ì¥"),
    key="nplus_condition"
)
if st.button("UID ì¶”ì¶œ ì‹¤í–‰", key="nplus_run"):
    if not selected_for_nplus:
        st.error("ìµœì†Œ 1ê°œ ì´ìƒì˜ CSV íŒŒì¼ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
    else:
        if threshold > len(selected_for_nplus) and len(selected_for_nplus) > 0:
            st.warning(f"ì„ íƒí•œ CSV íŒŒì¼ì€ {len(selected_for_nplus)}ê°œì¸ë°, {threshold}ê°œ ì´ìƒì„ ì„ íƒí•˜ì…¨ìŠµë‹ˆë‹¤. ê²°ê³¼ê°€ ì—†ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        uid_count = {}
        for fname in selected_for_nplus:
            orig_key = [k for k, v in st.session_state["file_names"].items() if v == fname][0]
            current_uids = get_uid_set(orig_key)
            for uid in current_uids:
                uid_count[uid] = uid_count.get(uid, 0) + 1
        if condition_option == "Në²ˆ ì´ìƒ ë“±ì¥":
            valid_uids = [uid for uid, cnt in uid_count.items() if cnt >= threshold]
            st.write(f"{threshold}ê°œ ì´ìƒ ë“±ì¥í•˜ëŠ” UID ìˆ˜: {len(valid_uids)}")
        else:
            valid_uids = [uid for uid, cnt in uid_count.items() if cnt == threshold]
            st.write(f"ì •í™•íˆ {threshold}ê°œ ë“±ì¥í•˜ëŠ” UID ìˆ˜: {len(valid_uids)}")
        if valid_uids:
            result_df = pd.DataFrame(sorted(valid_uids))
            filename = "result_n_or_more.csv" if condition_option == "Në²ˆ ì´ìƒ ë“±ì¥" else "result_exactly_n.csv" # íŒŒì¼ëª… ìˆ˜ì •
            save_to_session_and_download(result_df, filename)
        else:
            st.warning("í•´ë‹¹ ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ” UIDê°€ ì—†ìŠµë‹ˆë‹¤.")

# ------------------------------------------------------------------------------
# G. ì¤‘ë³µ ì œê±° (Unique)
# ------------------------------------------------------------------------------
st.subheader("5) ì¤‘ë³µ ì œê±°")
unique_target = st.selectbox(
    "ì¤‘ë³µ ì œê±°í•  CSV ì„ íƒ",
    ["--- ì„ íƒí•˜ì„¸ìš” ---"] + list(st.session_state["file_names"].values()),
    key="unique_select"
)
if st.button("ì¤‘ë³µ ì œê±° ì‹¤í–‰í•˜ê¸°", key="unique_run"):
    if unique_target == "--- ì„ íƒí•˜ì„¸ìš” ---":
        st.error("ì¤‘ë³µ ì œê±°í•  íŒŒì¼ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
    else:
        orig_key = [k for k, v in st.session_state["file_names"].items() if v == unique_target][0]
        df = st.session_state["csv_dataframes"][orig_key]
        df_unique = df.drop_duplicates(keep="first")
        st.write(f"ì›ë³¸ í–‰ ìˆ˜: {len(df)}, ì¤‘ë³µ ì œê±° í›„ í–‰ ìˆ˜: {len(df_unique)}")
        base_name, ext = os.path.splitext(unique_target) # os.path.splitext ì‚¬ìš©
        save_to_session_and_download(df_unique, f"{base_name}_unique{ext}") # íŒŒì¼ëª… ìˆ˜ì •


# ------------------------------------------------------------------------------
# H. ëœë¤ ì¶”ì¶œ
# ------------------------------------------------------------------------------
st.subheader("6) ëœë¤ ì¶”ì¶œ")
random_targets = st.multiselect(
    "ëœë¤ ì¶”ì¶œ ëŒ€ìƒ CSV ì„ íƒ (1ê°œ ì´ìƒ)",
    list(st.session_state["file_names"].values()),
    key="random_select"
)
sample_size = st.number_input("ëœë¤ ì¶”ì¶œ ê°œìˆ˜", min_value=1, value=10, step=1, key="random_sample_size")
if st.button("ëœë¤ ì¶”ì¶œ ì‹¤í–‰í•˜ê¸°", key="random_run"):
    if not random_targets:
        st.error("ìµœì†Œ 1ê°œ ì´ìƒì˜ íŒŒì¼ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
    else:
        combined_df = pd.DataFrame()
        for rt in random_targets:
            orig_key = [k for k, v in st.session_state["file_names"].items() if v == rt][0]
            combined_df = pd.concat([combined_df, st.session_state["csv_dataframes"][orig_key]], ignore_index=True)
        if len(combined_df) == 0:
            st.warning("ì„ íƒí•œ íŒŒì¼ë“¤ì˜ ë°ì´í„°ê°€ ë¹„ì–´ìˆì–´ ëœë¤ ì¶”ì¶œì„ í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        elif sample_size > len(combined_df):
            st.warning(f"ëœë¤ ì¶”ì¶œ ê°œìˆ˜({sample_size})ê°€ ì´ í–‰ ìˆ˜({len(combined_df)})ë³´ë‹¤ ë§ìŠµë‹ˆë‹¤. ê°€ëŠ¥í•œ ìµœëŒ€ ê°œìˆ˜ë§Œí¼ ì¶”ì¶œí•©ë‹ˆë‹¤.")
            sample_size = len(combined_df)
        if len(combined_df) > 0: # ë°ì´í„°ê°€ ìˆì„ ë•Œë§Œ sample ì‹¤í–‰
            random_sample = combined_df.sample(n=sample_size, random_state=None) # random_state=Noneìœ¼ë¡œ ë§¤ë²ˆ ë‹¤ë¥´ê²Œ
            st.write(f"í†µí•©ëœ í–‰ ìˆ˜: {len(combined_df)}, ëœë¤ ì¶”ì¶œ ê°œìˆ˜: {len(random_sample)}")
            save_to_session_and_download(random_sample, "result_random_sample.csv") # íŒŒì¼ëª… ìˆ˜ì •

# ------------------------------------------------------------------------------
# I. Bingo ë‹¹ì²¨ì ì¶”ì¶œ (ê¸°ì¡´ ì½”ë“œì™€ ìœ ì‚¬í•˜ê²Œ ìœ ì§€, Streamlit ìš”ì†Œì— key ì¶”ê°€)
# ------------------------------------------------------------------------------
st.subheader("7) ë¹™ê³  ë‹¹ì²¨ì ì¶”ì¶œ") # ë²ˆí˜¸ ìˆ˜ì •
bingo_size_options = ["2x2", "3x3", "4x4", "5x5"]
default_bingo_size_idx = 1
if "bingo_size_selection" in st.session_state:
    try:
        default_bingo_size_idx = bingo_size_options.index(st.session_state.bingo_size_selection)
    except ValueError:
        st.session_state.bingo_size_selection = bingo_size_options[default_bingo_size_idx]

bingo_size_selection = st.selectbox(
    "ë¹™ê³ íŒ í¬ê¸° ì„ íƒ", bingo_size_options, index=default_bingo_size_idx, key="bingo_size_selector_key_main"
)
if st.session_state.get("bingo_size_selection") != bingo_size_selection:
    st.session_state.bingo_size_selection = bingo_size_selection

size_map = {"2x2": 2, "3x3": 3, "4x4": 4, "5x5": 5}
n = size_map[bingo_size_selection]

cell_files = [None] * (n * n)
st.markdown("### ë¹™ê³ íŒ êµ¬ì„± (ë²ˆí˜¸ ìˆœì„œëŒ€ë¡œ CSV ì„ íƒ)")
available_files_for_bingo = ["---"] + list(st.session_state.get("file_names", {}).values())

if len(available_files_for_bingo) > 1:
    for r_bingo in range(n):
        cols_bingo = st.columns(n)
        for c_bingo in range(n):
            idx_bingo = r_bingo * n + c_bingo
            with cols_bingo[c_bingo]:
                cell_session_key = f"bingo_cell_selection_{n}_{idx_bingo}"
                selectbox_key = f"selectbox_cell_ui_{n}_{idx_bingo}"
                current_selection_for_cell = st.session_state.get(cell_session_key, "---")
                current_selection_idx = 0
                if current_selection_for_cell in available_files_for_bingo:
                    current_selection_idx = available_files_for_bingo.index(current_selection_for_cell)
                else:
                    st.session_state[cell_session_key] = "---"
                option = st.selectbox(
                    f"{idx_bingo+1}ë²ˆ ì¹¸", available_files_for_bingo, index=current_selection_idx, key=selectbox_key
                )
                if st.session_state.get(cell_session_key) != option:
                    st.session_state[cell_session_key] = option
                if option != "---":
                    cell_files[idx_bingo] = option
else:
    st.warning("ë¹™ê³ íŒì„ êµ¬ì„±í•˜ë ¤ë©´ ë¨¼ì € CSV íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê³  ë¡œë“œí•´ì£¼ì„¸ìš”.")

def get_bingo_lines(n_val):
    lines = []
    for r_val in range(n_val): lines.append([r_val * n_val + c_val for c_val in range(n_val)])
    for c_val in range(n_val): lines.append([r_val * n_val + c_val for r_val in range(n_val)])
    lines.append([i * n_val + i for i in range(n_val)])
    lines.append([i * n_val + (n_val - 1 - i) for i in range(n_val)])
    return lines

if st.button("ë‹¹ì²¨ì ì¶”ì¶œí•˜ê¸°", key="run_bingo_extraction_key_main"):
    current_cell_files = [None] * (n * n)
    for r_bingo_final in range(n):
        for c_bingo_final in range(n):
            idx_bingo_final = r_bingo_final * n + c_bingo_final
            cell_session_key_final = f"bingo_cell_selection_{n}_{idx_bingo_final}"
            selected_file_for_cell = st.session_state.get(cell_session_key_final, "---")
            if selected_file_for_cell != "---":
                current_cell_files[idx_bingo_final] = selected_file_for_cell
            else:
                current_cell_files[idx_bingo_final] = None
    
    if not any(f for f in current_cell_files if f is not None):
        st.error("ë¹™ê³ íŒì— CSV íŒŒì¼ì„ í•˜ë‚˜ ì´ìƒ ì„ íƒí•´ì£¼ì„¸ìš”.")
    else:
        uid_sets, counts = [], []
        file_names_map = st.session_state.get("file_names", {})
        csv_dataframes = st.session_state.get("csv_dataframes", {})
        for display_name_in_cell in current_cell_files:
            if display_name_in_cell:
                original_file_key = next((k for k, v in file_names_map.items() if v == display_name_in_cell), None)
                if original_file_key and original_file_key in csv_dataframes:
                    df_bingo = csv_dataframes[original_file_key]
                    if not df_bingo.empty and df_bingo.shape[1] > 0:
                        s = set(df_bingo.iloc[:, 0].astype(str))
                        uid_sets.append(s)
                        counts.append(len(s))
                    else:
                        uid_sets.append(set()); counts.append(0)
                else:
                    uid_sets.append(set()); counts.append(0)
                    st.warning(f"ê²½ê³ : ë¹™ê³  ì…€ íŒŒì¼ '{display_name_in_cell}'ì— ëŒ€í•œ ë°ì´í„°ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            else:
                uid_sets.append(set()); counts.append(0)
        lines = get_bingo_lines(n)
        line_sets = []
        for ln_indices in lines:
            inter = set()
            if ln_indices and uid_sets[ln_indices[0]]:
                inter = uid_sets[ln_indices[0]].copy()
                for i_idx in ln_indices[1:]:
                    if uid_sets[i_idx]: inter &= uid_sets[i_idx]
                    else: inter = set(); break
            line_sets.append(inter)
        user_count = defaultdict(int)
        for s_set in line_sets:
            for uid_val in s_set: user_count[uid_val] += 1
        
        fig, ax = plt.subplots(figsize=(n * 2, n * 2))
        ax.set_xlim(0, n); ax.set_ylim(0, n)
        ax.set_xticks(range(n + 1)); ax.set_yticks(range(n + 1))
        ax.grid(True, zorder=0)
        cmap = plt.get_cmap('tab20', len(lines))
        colors = [cmap(i) for i in range(len(lines))]
        for i, ln_indices in enumerate(lines):
            xs = [(idx % n) + 0.5 for idx in ln_indices]
            ys = [n - (idx // n) - 0.5 for idx in ln_indices]
            ax.plot(xs, ys, color=colors[i], linewidth=3, zorder=1, alpha=0.7)
        for idx_patch in range(n * n):
            r_patch, c_patch = divmod(idx_patch, n)
            ax.add_patch(Rectangle((c_patch, n - r_patch - 1), 1, 1, fill=False, edgecolor='gray', linewidth=1, zorder=2))
            file_display_name = current_cell_files[idx_patch] or '---'
            if len(file_display_name) > 12 and n <= 3: file_display_name = file_display_name[:10] + "\n" + file_display_name[10:20]
            elif len(file_display_name) > 18 : file_display_name = file_display_name[:15] + "\n" + file_display_name[15:30]
            txt = f"{file_display_name}\n({counts[idx_patch]})"
            ax.text(c_patch + 0.5, n - r_patch - 0.5, txt, ha='center', va='center', fontsize=6 if n>=4 else 8,
                    bbox=dict(facecolor='white', edgecolor='none', pad=0.2, alpha=0.9), zorder=3)
        base_offset = 0.55 if n <=3 else 0.65
        for i, ln_indices in enumerate(lines):
            if line_sets[i]:
                xs = [(idx % n) + 0.5 for idx in ln_indices]; ys = [n - (idx // n) - 0.5 for idx in ln_indices]
                if not xs or not ys: continue
                mx, my = sum(xs) / len(xs), sum(ys) / len(ys)
                angle_rad = math.atan2(my - n / 2, mx - n / 2) if n > 0 else 0
                current_offset = base_offset
                is_diag1 = (ln_indices == [k_val * n + k_val for k_val in range(n)])
                is_diag2 = (ln_indices == [k_val * n + (n - 1 - k_val) for k_val in range(n)])
                if (is_diag1 or is_diag2) and n > 2: current_offset = base_offset * 1.3
                dx = current_offset * math.cos(angle_rad); dy = current_offset * math.sin(angle_rad)
                label_x, label_y = mx + dx, my + dy
                ax.text(label_x, label_y, str(len(line_sets[i])), color=colors[i], fontsize=8 if n >=4 else 10,
                        fontweight='bold', ha='center', va='center',
                        bbox=dict(facecolor='white', edgecolor=colors[i], alpha=1.0, pad=0.3), zorder=5)
        ax.set_title(f"{n}x{n} ë¹™ê³ íŒ ì‹œê°í™”", fontsize=12); ax.axis('off')
        st.pyplot(fig)
        line_names = []
        for r_idx in range(n): line_names.append(f"ê°€ë¡œ {r_idx+1}")
        for c_idx in range(n): line_names.append(f"ì„¸ë¡œ {c_idx+1}")
        line_names.append("ëŒ€ê°ì„  \\"); line_names.append("ëŒ€ê°ì„  /")
        info_data = []
        for idx, ln_indices_info in enumerate(lines):
            current_line_name = line_names[idx] if idx < len(line_names) else f"ë¼ì¸ {idx+1}"
            info_data.append({
                "ë¹™ê³  ë¼ì¸": current_line_name, "ì…€ ë²ˆí˜¸ (0-indexed)": str(ln_indices_info), "ë‹¬ì„±ì ìˆ˜": len(line_sets[idx])
            })
        st.dataframe(pd.DataFrame(info_data))
        st.markdown("---")
        zip_lines_buf = io.BytesIO(); lines_zip_created = False
        with zipfile.ZipFile(zip_lines_buf, mode='w') as zf_lines:
            for i, line_name_zip in enumerate(line_names):
                uids_in_line = list(line_sets[i])
                if uids_in_line:
                    dfw = pd.DataFrame(uids_in_line, columns=['UID']).sort_values(by='UID').reset_index(drop=True)
                    safe_line_name = line_name_zip.replace(" ", "_").replace("\\", "diag1").replace("/", "diag2")
                    zf_lines.writestr(f"bingo_line_{safe_line_name}_winners.csv", dfw.to_csv(index=False, header=True).encode('utf-8-sig'))
                    lines_zip_created = True
        if lines_zip_created:
            zip_lines_buf.seek(0)
            st.download_button(
                label="ê° ë¼ì¸ë³„ ë‹¹ì²¨ì ëª©ë¡ ZIP ë‹¤ìš´ë¡œë“œ", data=zip_lines_buf,
                file_name=f"bingo_{n}x{n}_lines_winners.zip", mime="application/zip", key="download_bingo_lines_zip_key_main"
            )
        else: st.info("ë¹™ê³ ë¥¼ ë‹¬ì„±í•œ ë¼ì¸ì´ ì—†ì–´ 'ê° ë¼ì¸ë³„ ë‹¹ì²¨ì ëª©ë¡'ì„ ë‹¤ìš´ë¡œë“œí•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        st.markdown("---")
        st.markdown("### N-ë¹™ê³  ë‹¬ì„±ì ëª©ë¡ (ì •í™•íˆ Nê°œ ë¼ì¸ ë‹¬ì„±)")
        if user_count:
            winners_by_exact_bingo_count = defaultdict(list)
            for uid, count_val in user_count.items():
                if count_val > 0: winners_by_exact_bingo_count[count_val].append(uid)
            if winners_by_exact_bingo_count:
                zip_exact_buf = io.BytesIO(); exact_zip_created = False
                with zipfile.ZipFile(zip_exact_buf, mode='w') as zf_exact:
                    max_possible_bingos = len(lines)
                    for num_bingos in range(1, max_possible_bingos + 1):
                        if num_bingos in winners_by_exact_bingo_count:
                            uids_for_exact_count = sorted(list(winners_by_exact_bingo_count[num_bingos]))
                            if uids_for_exact_count:
                                df_exact_winners = pd.DataFrame(uids_for_exact_count, columns=['UID'])
                                csv_content = df_exact_winners.to_csv(index=False, header=True).encode('utf-8-sig')
                                zf_exact.writestr(f"bingo_winners_{num_bingos}_lines.csv", csv_content); exact_zip_created = True
                if exact_zip_created:
                    zip_exact_buf.seek(0)
                    st.download_button(
                        label=f"N-ë¹™ê³  ë‹¬ì„±ì ëª©ë¡ ZIP ë‹¤ìš´ë¡œë“œ (ë¹™ê³  ìˆ˜ë³„ íŒŒì¼)", data=zip_exact_buf,
                        file_name=f"bingo_{n}x{n}_winners_by_exact_line_count.zip", mime="application/zip", key="download_exact_bingo_count_zip_key_main"
                    )
                else: st.info("N-ë¹™ê³  ë‹¬ì„±ì ë°ì´í„°ëŠ” ìˆìœ¼ë‚˜, ë‹¤ìš´ë¡œë“œí•  íŒŒì¼ì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            else: st.info("ë¹™ê³ ë¥¼ 1ê°œ ì´ìƒ ë‹¬ì„±í•œ ì‚¬ìš©ìê°€ ì—†ì–´ N-ë¹™ê³ ë³„ ëª©ë¡ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        else: st.info("ë¹™ê³ ë¥¼ ë‹¬ì„±í•œ ì‚¬ìš©ìê°€ ì—†ì–´ N-ë¹™ê³ ë³„ ëª©ë¡ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        st.markdown("---")
        st.markdown("### Nê°œ ì´ìƒ ë¹™ê³  ë‹¬ì„±ì ëª©ë¡")
        num_input_key_at_least_n = f"min_bingo_lines_input_{n}"
        if num_input_key_at_least_n not in st.session_state: st.session_state[num_input_key_at_least_n] = 1
        max_bingo_val = len(lines) if lines else 1
        min_bingo_lines = st.number_input(
            "ì¶”ì¶œí•  ìµœì†Œ ë¹™ê³  ë¼ì¸ ìˆ˜ (N)", min_value=1, max_value=max_bingo_val,
            value=st.session_state[num_input_key_at_least_n], step=1, key=num_input_key_at_least_n,
            on_change=lambda: st.session_state.update({num_input_key_at_least_n: st.session_state[num_input_key_at_least_n]})
        )
        if st.button("Nê°œ ì´ìƒ ë¹™ê³  ë‹¬ì„±ì ëª©ë¡ ë³´ê¸°", key="view_multi_bingo_winners_key_main"):
            if user_count:
                current_min_lines = st.session_state[num_input_key_at_least_n]
                winners_n_bingo = {uid: count_val for uid, count_val in user_count.items() if count_val >= current_min_lines}
                if winners_n_bingo:
                    df_multi_bingo = pd.DataFrame(list(winners_n_bingo.items()), columns=['UID', 'ë‹¬ì„± ë¼ì¸ ìˆ˜'])
                    df_multi_bingo = df_multi_bingo.sort_values(by=['ë‹¬ì„± ë¼ì¸ ìˆ˜', 'UID'], ascending=[False, True]).reset_index(drop=True)
                    st.write(f"#### {current_min_lines}ê°œ ì´ìƒ ë¹™ê³  ë‹¬ì„±ì ({len(df_multi_bingo)}ëª…)")
                    st.dataframe(df_multi_bingo)
                    csv_multi_bingo = df_multi_bingo.to_csv(index=False).encode('utf-8-sig')
                    st.download_button(
                        label=f"{current_min_lines}ê°œ ì´ìƒ ë¹™ê³  ë‹¬ì„±ì CSV ë‹¤ìš´ë¡œë“œ", data=csv_multi_bingo,
                        file_name=f"bingo_winners_{current_min_lines}_or_more_lines.csv", mime="text/csv", key="download_multi_bingo_winners_csv_key_main"
                    )
                else: st.info(f"{current_min_lines}ê°œ ì´ìƒì˜ ë¹™ê³ ë¥¼ ë‹¬ì„±í•œ ì‚¬ìš©ìê°€ ì—†ìŠµë‹ˆë‹¤.")
            else: st.info("ë¹™ê³ ë¥¼ ë‹¬ì„±í•œ ì‚¬ìš©ìê°€ ì—†ì–´ Nê°œ ì´ìƒ ë¹™ê³  ë‹¬ì„±ì ëª©ë¡ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

# ------------------------------------------------------------------------------
# J. íŠ¹ì • ì—´(ì»¬ëŸ¼) ì‚­ì œí•˜ê¸°
# ------------------------------------------------------------------------------
st.subheader("8) íŠ¹ì • ì—´(ì»¬ëŸ¼) ì‚­ì œí•˜ê¸°") # ë²ˆí˜¸ ìˆ˜ì •
column_delete_target = st.selectbox(
    "ì—´ ì‚­ì œí•  CSVë¥¼ ì„ íƒí•˜ì„¸ìš”",
    ["--- ì„ íƒí•˜ì„¸ìš” ---"] + list(st.session_state["file_names"].values()),
    key="col_delete_select_main"
)
use_header_for_delete = st.checkbox("CSV ì²« í–‰ì„ í—¤ë”ë¡œ ì‚¬ìš©í•˜ê¸° (ì²´í¬ ì‹œ, ì²« í–‰ì„ ì»¬ëŸ¼ëª…ìœ¼ë¡œ ê°„ì£¼)", key="col_delete_header_main")
if column_delete_target != "--- ì„ íƒí•˜ì„¸ìš” ---":
    orig_key_delete = [k for k, v in st.session_state["file_names"].items() if v == column_delete_target][0]
    df_for_delete = st.session_state["csv_dataframes"][orig_key_delete]
    df_temp_delete = df_for_delete.copy()
    if use_header_for_delete and not df_temp_delete.empty:
        df_temp_delete.columns = df_temp_delete.iloc[0].astype(str)
        df_temp_delete = df_temp_delete[1:].reset_index(drop=True)
    columns_list_delete = [str(col) for col in df_temp_delete.columns.tolist()]
    selected_cols_to_delete = st.multiselect(
        "ì‚­ì œí•  ì—´ì„ ì„ íƒí•˜ì„¸ìš”", options=columns_list_delete, key="col_delete_multiselect_main"
    )
    if st.button("ì—´ ì‚­ì œ ì‹¤í–‰", key="col_delete_run_main"):
        if not selected_cols_to_delete:
            st.warning("ìµœì†Œ í•œ ê°œ ì´ìƒì˜ ì—´ì„ ì„ íƒí•´ ì£¼ì„¸ìš”.")
        else:
            df_after_delete = df_temp_delete.drop(columns=selected_cols_to_delete, errors="ignore")
            base_name, ext = os.path.splitext(column_delete_target)
            new_file_name_deleted = f"{base_name}_cols_removed{ext}"
            save_to_session_and_download(df_after_delete, new_file_name_deleted)
            st.success(f"ì„ íƒí•œ ì—´ì´ ì‚­ì œëœ íŒŒì¼ '{new_file_name_deleted}'ì´(ê°€) ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.")

# ------------------------------------------------------------------------------
# K. Nê°œë¡œ ë¶„í• í•˜ê¸°
# ------------------------------------------------------------------------------
st.subheader("9) íŒŒì¼ ë¶„í• í•˜ê¸°") # ë²ˆí˜¸ ìˆ˜ì •
split_target = st.selectbox(
    "ë¶„í• í•  CSVë¥¼ ì„ íƒí•˜ì„¸ìš”",
    ["--- ì„ íƒí•˜ì„¸ìš” ---"] + list(st.session_state["file_names"].values()),
    key="split_select_main"
)
n_parts = st.number_input("ëª‡ ê°œë¡œ ë¶„í• í• ê¹Œìš”?", min_value=2, value=2, step=1, key="split_n_parts_main")
if st.button("íŒŒì¼ ë¶„í•  ì‹¤í–‰", key="split_run_main"):
    if split_target == "--- ì„ íƒí•˜ì„¸ìš” ---":
        st.error("ë¶„í• í•  íŒŒì¼ì„ ì„ íƒí•´ ì£¼ì„¸ìš”.")
    else:
        orig_key_split = [k for k, v in st.session_state["file_names"].items() if v == split_target][0]
        df_to_split = st.session_state["csv_dataframes"][orig_key_split]
        total_rows = len(df_to_split)
        if total_rows == 0:
            st.warning("ì„ íƒí•œ íŒŒì¼ì´ ë¹„ì–´ìˆì–´ ë¶„í• í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        elif n_parts > total_rows:
            st.warning(f"ë¶„í•  ê°œìˆ˜({n_parts})ê°€ ì „ì²´ í–‰ ìˆ˜({total_rows})ë³´ë‹¤ ë§ìŠµë‹ˆë‹¤. ê° íŒŒì¼ì— 1í–‰ì”©, ì´ {total_rows}ê°œë¡œ ë¶„í• í•©ë‹ˆë‹¤.")
            n_parts = total_rows
        if total_rows > 0:
            base_chunk = total_rows // n_parts
            remainder = total_rows % n_parts
            st.write(f"ì´ í–‰ ìˆ˜: {total_rows}, ë¶„í•  ê°œìˆ˜: {n_parts}")
            st.write(f"ê° íŒŒíŠ¸ ê¸°ë³¸ í¬ê¸°: {base_chunk}, ë‚˜ë¨¸ì§€ ë¶„ë°° íŒŒíŠ¸ ìˆ˜: {remainder}")
            start_idx = 0
            for i in range(n_parts):
                chunk_size = base_chunk + (1 if i < remainder else 0)
                if chunk_size == 0: continue
                end_idx = start_idx + chunk_size
                df_chunk = df_to_split.iloc[start_idx:end_idx].reset_index(drop=True)
                name_part, ext_part = os.path.splitext(split_target)
                part_file_name = f"{name_part}_part{i+1}{ext_part}"
                save_to_session_and_download(df_chunk, part_file_name)
                st.info(f"{part_file_name} : í–‰ {start_idx+1} ~ {end_idx} (ì´ {chunk_size}í–‰) ìƒì„± ì™„ë£Œ")
                start_idx = end_idx

# ------------------------------------------------------------------------------
# L. ì‚¬ìš©ì ì§€ì • íŒŒì¼ ìˆœì„œ ë° ë§¤íŠ¸ë¦­ìŠ¤ ì¶œë ¥
# ------------------------------------------------------------------------------
st.subheader("10) ì‚¬ìš©ì ì§€ì • íŒŒì¼ ìˆœì„œ ë° ë§¤íŠ¸ë¦­ìŠ¤ ì¶œë ¥") # ë²ˆí˜¸ ìˆ˜ì •
all_available_files = list(st.session_state["file_names"].values())
if not all_available_files:
    st.warning("ì—…ë¡œë“œëœ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
else:
    st.markdown("**ë§¤íŠ¸ë¦­ìŠ¤ì— ì‚¬ìš©í•  íŒŒì¼ ìˆœì„œë¥¼ ì§ì ‘ ì§€ì •í•´ì£¼ì„¸ìš”.**")
    default_file_count = min(2, len(all_available_files)) if len(all_available_files) > 0 else 1
    ordered_file_count = st.number_input("ë§¤íŠ¸ë¦­ìŠ¤ì— ì‚¬ìš©í•  íŒŒì¼ ê°œìˆ˜", 
                                           min_value=1, max_value=len(all_available_files), 
                                           value=default_file_count, step=1, key="matrix_file_count_main")
    ordered_files_for_matrix = []
    temp_available_files = list(all_available_files)
    for i in range(int(ordered_file_count)):
        file_sel = st.selectbox(f"{i+1}ë²ˆì§¸ íŒŒì¼ ì„ íƒ", temp_available_files, key=f"order_matrix_select_{i}") # key ìˆ˜ì •
        ordered_files_for_matrix.append(file_sel)
    if len(set(ordered_files_for_matrix)) < len(ordered_files_for_matrix) and ordered_file_count > 0 :
        st.error("ê°™ì€ íŒŒì¼ì´ ì—¬ëŸ¬ ë²ˆ ì„ íƒë˜ì—ˆìŠµë‹ˆë‹¤. ê° ìˆœì„œì—ëŠ” ì„œë¡œ ë‹¤ë¥¸ íŒŒì¼ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
    else:
        st.markdown("### ì¶œë ¥ í˜•ì‹ ì„ íƒ")
        representation_option = st.radio(
            "ì–´ë–»ê²Œ ê²°ê³¼ë¥¼ í‘œì‹œí• ê¹Œìš”?", ("ì ˆëŒ€ê°’ (ë¹„ìœ¨)", "ì ˆëŒ€ê°’", "ë¹„ìœ¨"), key="representation_option_matrix_main"
        )
        if st.button("ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„±í•˜ê¸°", key="matrix_run_main"):
            uid_sets_matrix = {}
            for fname_matrix in ordered_files_for_matrix:
                orig_key_matrix = [k for k, v in st.session_state["file_names"].items() if v == fname_matrix][0]
                uid_sets_matrix[fname_matrix] = get_uid_set(orig_key_matrix)
            matrix_data = []; header_row = [""] + ordered_files_for_matrix; matrix_data.append(header_row)
            for i, file_i_name in enumerate(ordered_files_for_matrix):
                row_data = [file_i_name]; base_count_i = len(uid_sets_matrix[file_i_name])
                for j, file_j_name in enumerate(ordered_files_for_matrix):
                    if j < i: row_data.append("") 
                    else:
                        inter_count_ij = len(uid_sets_matrix[file_i_name].intersection(uid_sets_matrix[file_j_name]))
                        if representation_option == "ì ˆëŒ€ê°’": cell_val_str = str(inter_count_ij)
                        elif representation_option == "ë¹„ìœ¨":
                            ratio_val = (round(inter_count_ij / base_count_i * 100, 1) if base_count_i > 0 else 0.0)
                            cell_val_str = f"{ratio_val}%"
                        else:
                            ratio_val = (round(inter_count_ij / base_count_i * 100, 1) if base_count_i > 0 else 0.0)
                            cell_val_str = f"{inter_count_ij} ({ratio_val}%)"
                        row_data.append(cell_val_str)
                matrix_data.append(row_data)
            matrix_df_display = pd.DataFrame(matrix_data[1:], columns=matrix_data[0])
            st.write("### íŒŒì¼ ê°„ êµì§‘í•© ë§¤íŠ¸ë¦­ìŠ¤ (ií–‰ íŒŒì¼ ê¸°ì¤€)")
            st.dataframe(matrix_df_display)
            # save_to_session_and_download í•¨ìˆ˜ëŠ” CSVë§Œ ì €ì¥í•˜ë¯€ë¡œ, DataFrameì„ ì§ì ‘ ì €ì¥í•˜ë ¤ë©´ ë‹¤ë¥¸ ë°©ì‹ ì‚¬ìš©
            # ì—¬ê¸°ì„œëŠ” ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ë§Œ ì œê³µ
            csv_buffer_matrix = io.StringIO()
            matrix_df_display.to_csv(csv_buffer_matrix, index=False) # ì—¬ê¸°ì„œëŠ” í—¤ë” í¬í•¨ ì €ì¥
            st.download_button(label="êµì§‘í•© ë§¤íŠ¸ë¦­ìŠ¤ ë‹¤ìš´ë¡œë“œ", data=csv_buffer_matrix.getvalue(),
                               file_name="pairwise_intersection_matrix.csv", mime="text/csv",
                               key="download_pairwise_matrix")


            retention_matrix_data = []; header_row_retention = [""] + ordered_files_for_matrix
            retention_matrix_data.append(header_row_retention)
            for i, file_i_ret_name in enumerate(ordered_files_for_matrix):
                row_data_retention = [file_i_ret_name]; base_count_ret_i = len(uid_sets_matrix[file_i_ret_name])
                current_intersection_set = uid_sets_matrix[file_i_ret_name].copy()
                for j, file_j_ret_name in enumerate(ordered_files_for_matrix):
                    if j < i: row_data_retention.append("")  
                    else:
                        if j > i : current_intersection_set = current_intersection_set.intersection(uid_sets_matrix[file_j_ret_name])
                        abs_val_ret = len(current_intersection_set)
                        rate_ret = round(abs_val_ret / base_count_ret_i * 100, 1) if base_count_ret_i > 0 else 0.0
                        if representation_option == "ì ˆëŒ€ê°’": cell_val_ret_str = str(abs_val_ret)
                        elif representation_option == "ë¹„ìœ¨": cell_val_ret_str = f"{rate_ret}%"
                        else: cell_val_ret_str = f"{abs_val_ret} ({rate_ret}%)"
                        row_data_retention.append(cell_val_ret_str)
                retention_matrix_data.append(row_data_retention)
            retention_df_display = pd.DataFrame(retention_matrix_data[1:], columns=retention_matrix_data[0])
            st.write(f"### ì”ì¡´ìœ¨ ë§¤íŠ¸ë¦­ìŠ¤ ({ordered_files_for_matrix[0] if ordered_files_for_matrix else ''} ê¸°ì¤€ ì‹œì‘)") # ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°©ì§€
            st.dataframe(retention_df_display)
            # save_to_session_and_download(retention_df_display, "retention_matrix.csv")
            csv_buffer_retention = io.StringIO()
            retention_df_display.to_csv(csv_buffer_retention, index=False) # í—¤ë” í¬í•¨ ì €ì¥
            st.download_button(label="ì”ì¡´ìœ¨ ë§¤íŠ¸ë¦­ìŠ¤ ë‹¤ìš´ë¡œë“œ", data=csv_buffer_retention.getvalue(),
                               file_name="retention_matrix.csv", mime="text/csv",
                               key="download_retention_matrix")


# ------------------------------------------------------------------------------
# M. ë²¤ ë‹¤ì´ì–´ê·¸ë¨ ìƒì„± (matplotlib_venn ì„í¬íŠ¸ ì£¼ì˜)
# ------------------------------------------------------------------------------
st.subheader("11) ë²¤ ë‹¤ì´ì–´ê·¸ë¨ ìƒì„±")
selected_for_venn = st.multiselect(
    "ë²¤ ë‹¤ì´ì–´ê·¸ë¨ì— ì‚¬ìš©í•  CSV íŒŒì¼ ì„ íƒ (ìµœëŒ€ 3ê°œ)",
    list(st.session_state["file_names"].values()),
    key="venn_select_main"
)
if st.button("ë²¤ ë‹¤ì´ì–´ê·¸ë¨ ìƒì„±í•˜ê¸°", key="venn_run_main"):
    if not selected_for_venn:
        st.error("ìµœì†Œ 1ê°œì˜ CSV íŒŒì¼ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
    elif len(selected_for_venn) > 3:
        st.error("ë²¤ ë‹¤ì´ì–´ê·¸ë¨ì€ í˜„ì¬ 1~3ê°œì˜ ì§‘í•©ë§Œ ì§€ì›í•©ë‹ˆë‹¤.")
    else:
        try:
            from matplotlib_venn import venn2, venn3, venn2_circles, venn3_circles
            import matplotlib.patches as mpatches # mpatchesë„ ì—¬ê¸°ì„œ ì„í¬íŠ¸
        except ImportError:
            st.error("ë²¤ ë‹¤ì´ì–´ê·¸ë¨ì„ ìƒì„±í•˜ë ¤ë©´ 'matplotlib-venn' ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ í•„ìš”í•©ë‹ˆë‹¤. `pip install matplotlib-venn`ìœ¼ë¡œ ì„¤ì¹˜í•´ì£¼ì„¸ìš”.")
            st.stop()

        venn_sets_dict = {}
        venn_set_labels = []
        for fname_venn in selected_for_venn:
            orig_key_venn = [k for k, v in st.session_state["file_names"].items() if v == fname_venn][0]
            venn_sets_dict[fname_venn] = get_uid_set(orig_key_venn)
            venn_set_labels.append(fname_venn)
        
        fig_venn, ax_venn = plt.subplots(figsize=(8,8))
        plt.title(f"ë²¤ ë‹¤ì´ì–´ê·¸ë¨ ({len(selected_for_venn)} ì§‘í•©)", fontsize=14)
        if len(selected_for_venn) == 1:
            set1_venn = venn_sets_dict[venn_set_labels[0]]; count1 = len(set1_venn)
            circle = plt.Circle((0.5, 0.5), 0.4, color="skyblue", alpha=0.7)
            ax_venn.add_patch(circle)
            ax_venn.text(0.5, 0.5, f"{venn_set_labels[0]}\n({count1})", 
                         horizontalalignment='center', verticalalignment='center', fontsize=12, fontweight='bold')
            ax_venn.set_xlim(0, 1); ax_venn.set_ylim(0, 1); ax_venn.axis('off')
            legend_patch1 = mpatches.Patch(color='skyblue', label=f"{venn_set_labels[0]} ({count1})")
            ax_venn.legend(handles=[legend_patch1], loc="best", fontsize=10)
        elif len(selected_for_venn) == 2:
            set1_venn = venn_sets_dict[venn_set_labels[0]]; set2_venn = venn_sets_dict[venn_set_labels[1]]
            v = venn2([set1_venn, set2_venn], set_labels=tuple(venn_set_labels), ax=ax_venn,
                      set_colors=('skyblue', 'lightcoral'), alpha = 0.7)
            for text_id in ['10', '01', '11']:
                if v.get_label_by_id(text_id): v.get_label_by_id(text_id).set_fontsize(10)
            venn2_circles([set1_venn, set2_venn], linestyle='dashed', linewidth=1, color='grey', ax=ax_venn)
        elif len(selected_for_venn) == 3:
            set1_venn = venn_sets_dict[venn_set_labels[0]]; set2_venn = venn_sets_dict[venn_set_labels[1]]
            set3_venn = venn_sets_dict[venn_set_labels[2]]
            v = venn3([set1_venn, set2_venn, set3_venn], set_labels=tuple(venn_set_labels), ax=ax_venn,
                      set_colors=('skyblue', 'lightcoral', 'lightgreen'), alpha = 0.7)
            for text_id in ['100', '010', '001', '110', '101', '011', '111']:
                if v.get_label_by_id(text_id): v.get_label_by_id(text_id).set_fontsize(9)
            venn3_circles([set1_venn, set2_venn, set3_venn], linestyle='dashed', linewidth=1, color='grey', ax=ax_venn)
        st.pyplot(fig_venn)


st.markdown("---") # CSV ê¸°ëŠ¥ê³¼ ì›¹íˆ° ì¶”ì¶œ ê¸°ëŠ¥ êµ¬ë¶„

# ... (ê¸°ì¡´ Streamlit ì•± ì½”ë“œ ìƒë‹¨ì€ ë™ì¼) ...
# ... (Aë¶€í„° Mê¹Œì§€ì˜ CSV ê´€ë ¨ ê¸°ëŠ¥ ì½”ë“œëŠ” ì—¬ê¸°ì— ê·¸ëŒ€ë¡œ ìˆë‹¤ê³  ê°€ì •) ...

# ... (ê¸°ì¡´ Streamlit ì•± ì½”ë“œ ìƒë‹¨ì€ ë™ì¼) ...
# ... (Aë¶€í„° Mê¹Œì§€ì˜ CSV ê´€ë ¨ ê¸°ëŠ¥ ì½”ë“œëŠ” ì—¬ê¸°ì— ê·¸ëŒ€ë¡œ ìˆë‹¤ê³  ê°€ì •) ...

# ... (ê¸°ì¡´ Streamlit ì•± ì½”ë“œ ìƒë‹¨ì€ ë™ì¼) ...
# ... (Aë¶€í„° Mê¹Œì§€ì˜ CSV ê´€ë ¨ ê¸°ëŠ¥ ì½”ë“œëŠ” ì—¬ê¸°ì— ê·¸ëŒ€ë¡œ ìˆë‹¤ê³  ê°€ì •) ...

# ------------------------------------------------------------------------------
# N. ì¹´ì¹´ì˜¤í˜ì´ì§€ ì›¹íˆ° ì—…ë°ì´íŠ¸ ì¼ì ì¶”ì¶œ (XPath ìˆ˜ì • ë° ìƒì„¸ ë¡œê·¸ ê°•í™”)
# ------------------------------------------------------------------------------
st.header("ğŸŒ ì¹´ì¹´ì˜¤í˜ì´ì§€ ì›¹íˆ° ì •ë³´ ì¶”ì¶œ")
st.subheader("ì—…ë°ì´íŠ¸ ì¼ì ì¶”ì¶œ")

kakaopage_series_ids_input_kp = st.text_input(
    "ì¹´ì¹´ì˜¤í˜ì´ì§€ ì‘í’ˆ IDë¥¼ ì‰¼í‘œ(,)ë¡œ êµ¬ë¶„í•˜ì—¬ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: 59782511, 12345678)",
    key="kakaopage_ids_input_main_kp_v6" # í‚¤ ë³€ê²½
)

log_container_kp_v6 = st.container()
process_logs_kp_v6 = []

# ì‹¤ì œ ìŠ¤í¬ë˜í•‘ ë¡œì§ì„ ë‹´ë‹¹í•˜ëŠ” ë‚´ë¶€ í•¨ìˆ˜
def get_update_dates_for_series_internal_v6(series_id, driver, log_callback_ui_v6):
    url = f"https://page.kakao.com/content/{series_id}"
    log_callback_ui_v6(f"ID {series_id}: ìŠ¤í¬ë˜í•‘ ì‹œì‘. URL: {url}")
    driver.get(url)
    update_dates = []
    
    try:
        WebDriverWait(driver, 20).until( 
            EC.presence_of_element_located((By.XPATH, "//ul[contains(@class, 'jsx-3287026398')]"))
        )
        log_callback_ui_v6(f"ID {series_id}: ì´ˆê¸° íšŒì°¨ ëª©ë¡ ì»¨í…Œì´ë„ˆ(ul) ë¡œë“œ í™•ì¸.")
        time.sleep(3.5) # JavaScript ë° ë™ì  ì½˜í…ì¸  ë¡œë“œë¥¼ ìœ„í•œ ì¶©ë¶„í•œ ì´ˆê¸° ëŒ€ê¸° ì‹œê°„ (ì¡°ê¸ˆ ë” ëŠ˜ë¦¼)

        max_load_more_clicks = 35 # ë”ë³´ê¸° ë²„íŠ¼ í´ë¦­ ìµœëŒ€ ì‹œë„ íšŸìˆ˜ (ì¶©ë¶„íˆ í¬ê²Œ)
        no_new_content_streak = 0
        max_no_new_content_streak = 4 # 4ë²ˆ ì—°ì† ìƒˆ íšŒì°¨ ë¡œë“œ ì•ˆë˜ë©´ ì¤‘ë‹¨ (ë„¤íŠ¸ì›Œí¬ ì§€ì—° ë“± ê³ ë ¤)
        last_known_episode_elements_count = 0

        initial_items_count = len(driver.find_elements(By.XPATH, "//ul[contains(@class, 'jsx-3287026398')]/li"))
        log_callback_ui_v6(f"ID {series_id}: 'ë”ë³´ê¸°' ì „, ì´ˆê¸° ê°ì§€ëœ íšŒì°¨ ì•„ì´í…œ ìˆ˜: {initial_items_count}")

        for click_attempt in range(max_load_more_clicks):
            try:
                # í˜„ì¬ í™”ë©´ì— ìˆëŠ” ëª¨ë“  íšŒì°¨ì˜ ë‚ ì§œ ìš”ì†Œë“¤ì„ ê°€ì ¸ì˜´ (ìƒˆ ì½˜í…ì¸  ê°ì§€ìš©)
                current_episode_date_elements = driver.find_elements(By.XPATH, "//ul[contains(@class, 'jsx-3287026398')]/li//div[contains(@class, 'font-x-small1')]//span[@class='break-all align-middle'][1]")
                current_elements_count = len(current_episode_date_elements)
                log_callback_ui_v6(f"ID {series_id}: 'ë”ë³´ê¸°' ì‹œë„ {click_attempt + 1}/{max_load_more_clicks}. í˜„ì¬ ê°ì§€ëœ ë‚ ì§œ ìš”ì†Œ ìˆ˜: {current_elements_count}.")

                if current_elements_count == last_known_episode_elements_count and click_attempt > 0 :
                    no_new_content_streak += 1
                    log_callback_ui_v6(f"ID {series_id}: ìƒˆ ë‚ ì§œ ìš”ì†Œ ë³€í™” ì—†ìŒ ({no_new_content_streak}/{max_no_new_content_streak}).")
                    if no_new_content_streak >= max_no_new_content_streak:
                        log_callback_ui_v6(f"ID {series_id}: ì—°ì† {max_no_new_content_streak}íšŒ ìƒˆ ë‚ ì§œ ìš”ì†Œ ë³€í™” ì—†ì–´ 'ë”ë³´ê¸°' ì¤‘ë‹¨.")
                        break
                else:
                    no_new_content_streak = 0
                last_known_episode_elements_count = current_elements_count

                # --- "ë”ë³´ê¸°" ë²„íŠ¼ XPath ìˆ˜ì • (ì œê³µí•´ì£¼ì‹  Outer HTML ê¸°ë°˜) ---
                load_more_button_xpath = "//div[contains(@class, 'cursor-pointer') and .//img[@alt='ì•„ë˜ í™”ì‚´í‘œ']]"
                # --- XPath ìˆ˜ì • ë ---
                
                log_callback_ui_v6(f"ID {series_id}: ì‚¬ìš©ëœ 'ë”ë³´ê¸°' ë²„íŠ¼ XPath: {load_more_button_xpath}")
                
                # ë²„íŠ¼ì´ DOMì— ë‚˜íƒ€ë‚˜ê³  í´ë¦­ ê°€ëŠ¥í•  ë•Œê¹Œì§€ ëª…ì‹œì ìœ¼ë¡œ ëŒ€ê¸°
                load_more_button = WebDriverWait(driver, 15).until( # ëŒ€ê¸° ì‹œê°„ 15ì´ˆ
                    EC.element_to_be_clickable((By.XPATH, load_more_button_xpath))
                )
                log_callback_ui_v6(f"ID {series_id}: 'ë”ë³´ê¸°' ë²„íŠ¼ ì°¾ìŒ ë° í´ë¦­ ê°€ëŠ¥ ìƒíƒœ í™•ì¸.")
                
                # ë²„íŠ¼ì´ í™”ë©´ ì¤‘ì•™ì— ì˜¤ë„ë¡ ìŠ¤í¬ë¡¤ (í´ë¦­ ì •í™•ë„ í–¥ìƒ ë° ê°€ë ¤ì§ ë°©ì§€)
                driver.execute_script("arguments[0].scrollIntoView({block: 'center', inline: 'nearest'});", load_more_button)
                time.sleep(0.8) # ìŠ¤í¬ë¡¤ í›„ ë²„íŠ¼ì´ ì•ˆì •í™”ë  ì‹œê°„

                driver.execute_script("arguments[0].click();", load_more_button)
                log_callback_ui_v6(f"ID {series_id}: 'ë”ë³´ê¸°' ë²„íŠ¼ í´ë¦­ ì„±ê³µ ({click_attempt + 1}).")
                
                time.sleep(3.0) # ìƒˆ ì½˜í…ì¸  ë¡œë“œ ëŒ€ê¸° ì‹œê°„ (ì¶©ë¶„íˆ)

            except TimeoutException:
                log_callback_ui_v6(f"ID {series_id}: 'ë”ë³´ê¸°' ë²„íŠ¼ì„ ì‹œê°„ ë‚´ì— ì°¾ê±°ë‚˜ í´ë¦­í•  ìˆ˜ ì—†ìŒ (Timeout). ëª¨ë“  íšŒì°¨ ë¡œë“œ ì™„ë£Œë¡œ ê°„ì£¼.")
                break 
            except NoSuchElementException:
                log_callback_ui_v6(f"ID {series_id}: 'ë”ë³´ê¸°' ë²„íŠ¼ì„ ë” ì´ìƒ ì°¾ì„ ìˆ˜ ì—†ìŒ (NoSuchElement). ëª¨ë“  íšŒì°¨ ë¡œë“œ ì™„ë£Œë¡œ ê°„ì£¼.")
                break
            except ElementClickInterceptedException:
                log_callback_ui_v6(f"ID {series_id}: 'ë”ë³´ê¸°' ë²„íŠ¼ í´ë¦­ì´ ë‹¤ë¥¸ ìš”ì†Œì— ì˜í•´ ê°€ë¡œì±„ì§. í˜ì´ì§€ ë§¨ ì•„ë˜ë¡œ ìŠ¤í¬ë¡¤ í›„ ì¬ì‹œë„.")
                driver.execute_script("window.scrollTo(0, document.body.scrollHeight);")
                time.sleep(1.8) # ìŠ¤í¬ë¡¤ í›„ ì•ˆì •í™” ë° ì¬ì‹œë„ ëŒ€ê¸° (ì¡°ê¸ˆ ë” ëŠ˜ë¦¼)
            except Exception as e_load_more_v6:
                log_callback_ui_v6(f"ID {series_id}: 'ë”ë³´ê¸°' ê³¼ì • ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {str(e_load_more_v6)[:120]}. 'ë”ë³´ê¸°' ì¤‘ë‹¨.") # ì˜¤ë¥˜ ë©”ì‹œì§€ ê¸¸ì´ ì¡°ì ˆ
                break
        
        log_callback_ui_v6(f"ID {series_id}: 'ë”ë³´ê¸°' ê³¼ì • ì™„ë£Œ. ìµœì¢… ë‚ ì§œ ì¶”ì¶œ ì‹œì‘.")

        episode_list_item_xpath_final = "//ul[contains(@class, 'jsx-3287026398')]/li[contains(@class, 'list-child-item')]"
        list_item_elements_final = driver.find_elements(By.XPATH, episode_list_item_xpath_final)
        log_callback_ui_v6(f"ID {series_id}: ìµœì¢…ì ìœ¼ë¡œ ìŠ¤ìº”í•  íšŒì°¨ ì•„ì´í…œ li ìš”ì†Œ ìˆ˜: {len(list_item_elements_final)}.")
        
        if not list_item_elements_final:
            log_callback_ui_v6(f"ID {series_id}: [ê²½ê³ ] ìµœì¢… íšŒì°¨ ì•„ì´í…œ li ìš”ì†Œë¥¼ í•˜ë‚˜ë„ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

        date_pattern = re.compile(r"^\d{2}\.\d{2}\.\d{2}$")
        all_extracted_dates_in_order = []

        for idx, item_element_final in enumerate(list_item_elements_final):
            try:
                date_span_xpath_final = ".//div[contains(@class, 'font-x-small1') and contains(@class, 'text-el-50')]/span[@class='break-all align-middle'][1]"
                date_span_element = item_element_final.find_element(By.XPATH, date_span_xpath_final)
                date_text = date_span_element.text.strip()
                
                if date_pattern.match(date_text):
                    all_extracted_dates_in_order.append(date_text)
            except NoSuchElementException:
                pass 
            except Exception: 
                pass
        
        log_callback_ui_v6(f"ID {series_id}: ì´ {len(all_extracted_dates_in_order)}ê°œì˜ ë‚ ì§œ í…ìŠ¤íŠ¸ ì¶”ì¶œ (ì¤‘ë³µ í¬í•¨).")

        seen_dates = set()
        for d_item_final_v6 in all_extracted_dates_in_order: # ë³€ìˆ˜ëª… ì¶©ëŒ ë°©ì§€
            if d_item_final_v6 not in seen_dates:
                update_dates.append(d_item_final_v6)
                seen_dates.add(d_item_final_v6)
        
        if not update_dates:
            log_callback_ui_v6(f"ID {series_id}: [ê²°ê³¼] ìµœì¢…ì ìœ¼ë¡œ ì¶”ì¶œëœ ê³ ìœ  ì—…ë°ì´íŠ¸ ë‚ ì§œê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            log_callback_ui_v6(f"ID {series_id}: [ê²°ê³¼] {len(update_dates)}ê°œì˜ ê³ ìœ í•œ ì—…ë°ì´íŠ¸ ë‚ ì§œ ì¶”ì¶œ ì™„ë£Œ.")
                
    except TimeoutException:
        log_callback_ui_v6(f"ID {series_id}: [ì˜¤ë¥˜] í˜ì´ì§€ì˜ ì£¼ìš” ì»¨í…ì¸ (íšŒì°¨ ëª©ë¡) ë¡œë“œ ì‹œê°„ ì´ˆê³¼.")
    except Exception as e_global_scrape_final_v6:
        log_callback_ui_v6(f"ID {series_id}: [ì˜¤ë¥˜] ìŠ¤í¬ë˜í•‘ ì¤‘ ì˜ˆê¸°ì¹˜ ì•Šì€ ì „ì—­ ì˜¤ë¥˜ ë°œìƒ: {str(e_global_scrape_final_v6)[:150]}")
    
    return update_dates

@st.cache_data(ttl=3600, show_spinner=False)
def get_update_dates_for_series_cached_wrapper_v6(series_id, webdriver_options_dict): # ë³€ìˆ˜ëª… ë³€ê²½
    temp_logs_for_cache_v6 = []
    def append_log_for_cache_internal_v6(message):
        temp_logs_for_cache_v6.append(message)

    options = webdriver.ChromeOptions()
    for arg_name, arg_val in webdriver_options_dict.get("arguments", {}).items():
        if arg_val is None: options.add_argument(arg_name)
        else: options.add_argument(f"{arg_name}={arg_val}")
    for opt_name, opt_value in webdriver_options_dict.get("experimental_options", {}).items():
        options.add_experimental_option(opt_name, opt_value)

    driver_instance_cache_internal_v6 = None
    try:
        # ì‹œìŠ¤í…œ PATHì˜ ChromeDriver ì‚¬ìš©
        driver_instance_cache_internal_v6 = webdriver.Chrome(options=options)
        append_log_for_cache_internal_v6(f"ID {series_id}: ì‹œìŠ¤í…œ PATHì˜ ChromeDriverë¡œ ì„¸ì…˜ ìƒì„± ì‹œë„.")
        
        dates = get_update_dates_for_series_internal_v6(series_id, driver_instance_cache_internal_v6, append_log_for_cache_internal_v6)
        return dates, temp_logs_for_cache_v6
    except Exception as e_cache_internal_v6:
        append_log_for_cache_internal_v6(f"ID {series_id}: ìºì‹œëœ WebDriver ì‹¤í–‰ ì¤‘ ì‹¬ê°í•œ ì˜¤ë¥˜: {str(e_cache_internal_v6)}")
        import traceback
        append_log_for_cache_internal_v6(f"Traceback: {traceback.format_exc(limit=5)}")
        return [], temp_logs_for_cache_v6
    finally:
        if driver_instance_cache_internal_v6:
            driver_instance_cache_internal_v6.quit()
            append_log_for_cache_internal_v6(f"ID {series_id}: WebDriver ì„¸ì…˜ ì¢…ë£Œë¨.")

if st.button("ì—…ë°ì´íŠ¸ ì¼ì ì¶”ì¶œ ë° ZIP ë‹¤ìš´ë¡œë“œ", key="kakaopage_extract_button_main_kp_v6"): # í‚¤ ë³€ê²½
    if not kakaopage_series_ids_input_kp:
        st.warning("ì‘í’ˆ IDë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")
    else:
        series_ids_list_kp_v6 = [id_str.strip() for id_str in kakaopage_series_ids_input_kp.split(',') if id_str.strip()]
        if not series_ids_list_kp_v6:
            st.warning("ìœ íš¨í•œ ì‘í’ˆ IDê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            webdriver_options_dict_for_cache_final_kp_v6 = {
                "arguments": {
                    "--headless": None, "--no-sandbox": None, "--disable-dev-shm-usage": None,
                    "--disable-gpu": None,
                    "user-agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36",
                    "--lang": "ko_KR",
                    "--window-size": "1920,1080"
                },
                "experimental_options": {"excludeSwitches": ['enable-logging']}
            }
            
            results_for_zip_kp_v6 = {}
            total_ids_kp_v6 = len(series_ids_list_kp_v6)
            
            process_logs_kp_v6.clear()
            log_container_kp_v6.empty()
            log_display_area_kp_v6 = log_container_kp_v6.expander("ì‹¤ì‹œê°„ ì²˜ë¦¬ ë¡œê·¸ ë³´ê¸°", expanded=True)
            
            progress_bar_placeholder_kp_v6 = st.empty()
            current_status_text_kp_v6 = st.empty()
            overall_start_time_kp_v6 = time.time()

            with st.spinner(f"ì´ {total_ids_kp_v6}ê°œì˜ ì‘í’ˆ ì •ë³´ë¥¼ ì²˜ë¦¬ ì¤‘ì…ë‹ˆë‹¤..."):
                progress_bar_kp_v6 = progress_bar_placeholder_kp_v6.progress(0)
                
                for i, series_id_item_kp_v6 in enumerate(series_ids_list_kp_v6):
                    start_time_item_kp_v6 = time.time()
                    current_progress_kp_v6 = (i + 1) / total_ids_kp_v6
                    progress_bar_kp_v6.progress(current_progress_kp_v6)
                    current_status_text_kp_v6.text(f"ì²˜ë¦¬ ì¤‘: {series_id_item_kp_v6} ({i+1}/{total_ids_kp_v6})")
                    
                    process_logs_kp_v6.append(f"--- ID: {series_id_item_kp_v6} ì²˜ë¦¬ ì‹œì‘ ---")
                    with log_display_area_kp_v6: st.markdown(f"**ID: {series_id_item_kp_v6} ì²˜ë¦¬ ì‹œì‘...**")
                    
                    dates_kp_v6, item_logs_from_cache_kp_v6 = get_update_dates_for_series_cached_wrapper_v6(series_id_item_kp_v6, webdriver_options_dict_for_cache_final_kp_v6)
                    
                    process_logs_kp_v6.extend(item_logs_from_cache_kp_v6)
                    with log_display_area_kp_v6:
                        for log_msg_kp_v6 in item_logs_from_cache_kp_v6:
                            if "[ì˜¤ë¥˜]" in log_msg_kp_v6 or "[ê²½ê³ ]" in log_msg_kp_v6 or "ì˜¤ë¥˜:" in log_msg_kp_v6: st.warning(log_msg_kp_v6)
                            else: st.info(log_msg_kp_v6)
                    
                    if dates_kp_v6:
                        file_content_kp_v6 = "\n".join(dates_kp_v6)
                        safe_series_id_kp_v6 = re.sub(r'[\\/*?:"<>|]', "_", series_id_item_kp_v6)
                        filename_in_zip_kp_v6 = f"{safe_series_id_kp_v6}_updates.txt"
                        results_for_zip_kp_v6[filename_in_zip_kp_v6] = file_content_kp_v6
                        final_msg_kp_v6 = f"ID {series_id_item_kp_v6}: [ì„±ê³µ] {len(dates_kp_v6)}ê°œ ì—…ë°ì´íŠ¸ ì¼ì ì¶”ì¶œ ì™„ë£Œ."
                        process_logs_kp_v6.append(final_msg_kp_v6)
                        with log_display_area_kp_v6: st.success(final_msg_kp_v6)
                    else:
                        final_msg_kp_v6 = f"ID {series_id_item_kp_v6}: [ì‹¤íŒ¨] ì—…ë°ì´íŠ¸ ì¼ìë¥¼ ì°¾ì„ ìˆ˜ ì—†ê±°ë‚˜ ì¶”ì¶œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
                        process_logs_kp_v6.append(final_msg_kp_v6)
                        with log_display_area_kp_v6: st.error(final_msg_kp_v6)
                    
                    end_time_item_kp_v6 = time.time()
                    process_logs_kp_v6.append(f"ID {series_id_item_kp_v6} ì²˜ë¦¬ ì†Œìš” ì‹œê°„: {end_time_item_kp_v6 - start_time_item_kp_v6:.2f}ì´ˆ")
                    process_logs_kp_v6.append(f"--- ID: {series_id_item_kp_v6} ì²˜ë¦¬ ì¢…ë£Œ ---\n")
                    with log_display_area_kp_v6: st.markdown("---")
                    time.sleep(0.3)

            progress_bar_placeholder_kp_v6.empty()
            current_status_text_kp_v6.empty()
            overall_end_time_kp_v6 = time.time()
            process_logs_kp_v6.insert(0, f"**ì¹´ì¹´ì˜¤í˜ì´ì§€ ì¶”ì¶œ ì „ì²´ ì‘ì—… ì™„ë£Œ! ì´ ì†Œìš” ì‹œê°„: {overall_end_time_kp_v6 - overall_start_time_kp_v6:.2f}ì´ˆ**")

            if results_for_zip_kp_v6:
                log_final_summary_kp_v6 = "ëª¨ë“  ì‘í’ˆ ì²˜ë¦¬ ì™„ë£Œ. ZIP íŒŒì¼ ìƒì„± ì¤‘..."
                process_logs_kp_v6.append(log_final_summary_kp_v6)

                zip_buffer_kp_v6 = io.BytesIO()
                with zipfile.ZipFile(zip_buffer_kp_v6, "w", zipfile.ZIP_DEFLATED) as zf_kp_v6:
                    for filename_kp_v6, content_kp_v6 in results_for_zip_kp_v6.items():
                        zf_kp_v6.writestr(filename_kp_v6, content_kp_v6.encode('utf-8'))
                zip_buffer_kp_v6.seek(0)
                
                st.download_button(
                    label="ì¶”ì¶œëœ ì—…ë°ì´íŠ¸ ì¼ì ZIP ë‹¤ìš´ë¡œë“œ",
                    data=zip_buffer_kp_v6,
                    file_name="kakaopage_webtoon_updates.zip",
                    mime="application/zip",
                    key="download_kakaopage_zip_main_v6" # í‚¤ ë³€ê²½
                )
                process_logs_kp_v6.append("ZIP íŒŒì¼ ìƒì„± ì™„ë£Œ! ìœ„ ë²„íŠ¼ìœ¼ë¡œ ë‹¤ìš´ë¡œë“œí•˜ì„¸ìš”.")
                st.success("ì¹´ì¹´ì˜¤í˜ì´ì§€ ì—…ë°ì´íŠ¸ ì¼ì ZIP íŒŒì¼ ìƒì„± ì™„ë£Œ! ë‹¤ìš´ë¡œë“œ ë²„íŠ¼ì„ ì´ìš©í•˜ì„¸ìš”.")
            else:
                log_final_summary_kp_v6 = "ì¶”ì¶œëœ ë°ì´í„°ê°€ ì—†ì–´ ZIP íŒŒì¼ì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                process_logs_kp_v6.append(log_final_summary_kp_v6)
                st.warning(log_final_summary_kp_v6)
            
            log_container_kp_v6.empty()
            with st.expander("ì¹´ì¹´ì˜¤í˜ì´ì§€ ì¶”ì¶œ ì „ì²´ ìƒì„¸ ì²˜ë¦¬ ë¡œê·¸ ë³´ê¸°", expanded=True):
                for log_line_kp_v6 in process_logs_kp_v6:
                    if "ID:" in log_line_kp_v6 and "ì‹œì‘" in log_line_kp_v6 : st.markdown(f"**{log_line_kp_v6}**")
                    elif "[ì„±ê³µ]" in log_line_kp_v6: st.success(log_line_kp_v6)
                    elif "[ì‹¤íŒ¨]" in log_line_kp_v6 or "[ì˜¤ë¥˜]" in log_line_kp_v6 or "[ê²½ê³ ]" in log_line_kp_v6 or "ì˜¤ë¥˜:" in log_line_kp_v6 : st.error(log_line_kp_v6)
                    elif "ì†Œìš” ì‹œê°„" in log_line_kp_v6 or "ì²˜ë¦¬ ì¢…ë£Œ" in log_line_kp_v6: st.caption(log_line_kp_v6)
                    elif "ZIP íŒŒì¼" in log_line_kp_v6 or "ì´ ì†Œìš” ì‹œê°„" in log_line_kp_v6: st.info(log_line_kp_v6)
                    else: st.markdown(f"`{log_line_kp_v6}`")


# ------------------------------------------------------------------------------
# O. CSVì˜ UIDë¡œ ì¹´ì¹´ì˜¤í˜ì´ì§€ ê³µì§€ì‚¬í•­ íƒ­ ì—´ê¸° (ë¡œì»¬ ì‹¤í–‰ìš©)
# ------------------------------------------------------------------------------
st.subheader("13) CSVì˜ UIDë¡œ ì¹´ì¹´ì˜¤í˜ì´ì§€ ê³µì§€ì‚¬í•­ íƒ­ ì—´ê¸° (ë¡œì»¬ ì‹¤í–‰ ì „ìš©)") # ë²ˆí˜¸ëŠ” ê¸°ì¡´ ê¸°ëŠ¥ ìˆ˜ì— ë§ì¶° ì¡°ì •

st.warning("ì£¼ì˜: ì´ ê¸°ëŠ¥ì€ Streamlit ì•±ì„ ë¡œì»¬ PCì—ì„œ ì‹¤í–‰í•  ë•Œë§Œ ì •ìƒì ìœ¼ë¡œ ë™ì‘í•©ë‹ˆë‹¤. ì›¹ ì„œë²„ì— ë°°í¬ëœ ì•±ì—ì„œëŠ” ì‚¬ìš©ìì˜ ë¸Œë¼ìš°ì €ì— íƒ­ì„ ì§ì ‘ ì—´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.", icon="âš ï¸")

# ì„¸ì…˜ ìƒíƒœì—ì„œ íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
available_files_for_tab_opening = ["--- ì„ íƒí•˜ì„¸ìš” ---"] + list(st.session_state.get("file_names", {}).values())

selected_csv_for_tabs = st.selectbox(
    "UID ëª©ë¡ì´ í¬í•¨ëœ CSV íŒŒì¼ ì„ íƒ",
    available_files_for_tab_opening,
    key="selectbox_csv_for_tabs"
)

# time.sleep()ì„ ìœ„í•œ ì…ë ¥ í•„ë“œ
delay_between_tabs = st.number_input(
    "ê° íƒ­ì„ ì—´ ë•Œ ê°„ê²© (ì´ˆ)",
    min_value=0.1,
    max_value=5.0,
    value=0.5, # ê¸°ë³¸ê°’ 0.5ì´ˆ
    step=0.1,
    key="number_input_delay_tabs"
)

if st.button("ì„ íƒí•œ CSVì˜ UIDë¡œ ê³µì§€ì‚¬í•­ íƒ­ ëª¨ë‘ ì—´ê¸°", key="button_open_kakao_tabs"):
    if selected_csv_for_tabs == "--- ì„ íƒí•˜ì„¸ìš” ---":
        st.error("íƒ­ì„ ì—´ CSV íŒŒì¼ì„ ì„ íƒí•´ì£¼ì„¸ìš”.")
    else:
        # ì„ íƒëœ í‘œì‹œëª…ìœ¼ë¡œ ì›ë³¸ DataFrame ê°€ì ¸ì˜¤ê¸°
        original_key_for_tabs = next(
            (k for k, v in st.session_state.get("file_names", {}).items() if v == selected_csv_for_tabs), None
        )

        if original_key_for_tabs and original_key_for_tabs in st.session_state.get("csv_dataframes", {}):
            df_for_tabs = st.session_state["csv_dataframes"][original_key_for_tabs]

            if not df_for_tabs.empty and df_for_tabs.shape[1] > 0:
                # ì²« ë²ˆì§¸ ì—´ì„ UIDë¡œ ê°€ì • (ë¬¸ìì—´ë¡œ ë³€í™˜í•˜ê³  NaN ë° ë¹ˆ ë¬¸ìì—´ ì œê±°)
                uids_to_open = df_for_tabs.iloc[:, 0].astype(str).dropna()
                uids_to_open = [uid for uid in uids_to_open if uid.strip()] # ê³µë°±ë§Œ ìˆëŠ” UID ì œê±°

                if not uids_to_open:
                    st.warning(f"'{selected_csv_for_tabs}' íŒŒì¼ì˜ ì²« ë²ˆì§¸ ì—´ì— ìœ íš¨í•œ UIDê°€ ì—†ìŠµë‹ˆë‹¤.")
                else:
                    base_url_notice = "https://page.kakao.com/content/{}?tab_type=notice"
                    tabs_opened_count = 0
                    
                    # Chrome ë¸Œë¼ìš°ì €ë¥¼ ì‚¬ìš©í•˜ë„ë¡ ì‹œë„
                    try:
                        # íŠ¹ì • ë¸Œë¼ìš°ì €ë¥¼ ì§€ì •í•˜ë ¤ë©´ í•´ë‹¹ ë¸Œë¼ìš°ì €ì˜ ì‹¤í–‰ íŒŒì¼ ì´ë¦„ì„ ì •í™•íˆ ì•Œì•„ì•¼ í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
                        # 'chrome', 'firefox', 'safari', 'msie', 'opera' ë“±ì´ ì¼ë°˜ì ì…ë‹ˆë‹¤.
                        # Windows: webbrowser.register('chrome', None, webbrowser.BackgroundBrowser("C://Program Files (x86)//Google//Chrome//Application//chrome.exe")) (ê²½ë¡œ í™•ì¸ í•„ìš”)
                        # macOS: webbrowser.get('chrome') ë˜ëŠ” webbrowser.get('open -a /Applications/Google\ Chrome.app %s')
                        # Linux: webbrowser.get('google-chrome') ë˜ëŠ” webbrowser.get('chromium-browser')
                        # ì—¬ê¸°ì„œëŠ” ì¼ë°˜ì ì¸ 'chrome'ì„ ì‹œë„í•©ë‹ˆë‹¤. í™˜ê²½ì— ë”°ë¼ ë™ì‘í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
                        browser_controller = webbrowser.get(None) # ì‹œìŠ¤í…œ ê¸°ë³¸ ë¸Œë¼ìš°ì € ì‚¬ìš©
                        # browser_controller = webbrowser.get('chrome') # íŠ¹ì • ë¸Œë¼ìš°ì € ì‹œë„ (ì„¤ì¹˜ ë° í™˜ê²½ë³€ìˆ˜ ì„¤ì • í•„ìš”í•  ìˆ˜ ìˆìŒ)
                    except webbrowser.Error:
                        st.error("ì›¹ ë¸Œë¼ìš°ì €ë¥¼ ì œì–´í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì‹œìŠ¤í…œì— ê¸°ë³¸ ë¸Œë¼ìš°ì €ê°€ ì„¤ì •ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
                        st.stop() # ì˜¤ë¥˜ ë°œìƒ ì‹œ ì¤‘ë‹¨

                    st.info(f"'{selected_csv_for_tabs}' íŒŒì¼ì—ì„œ {len(uids_to_open)}ê°œì˜ UIDì— ëŒ€í•´ íƒ­ì„ ì—½ë‹ˆë‹¤...")
                    
                    with st.spinner(f"{len(uids_to_open)}ê°œì˜ íƒ­ì„ ì—¬ëŠ” ì¤‘... (ê° íƒ­ë‹¹ {delay_between_tabs}ì´ˆ ëŒ€ê¸°)"):
                        for uid_item in uids_to_open:
                            url_to_open = base_url_notice.format(uid_item.strip())
                            try:
                                browser_controller.open_new_tab(url_to_open)
                                tabs_opened_count += 1
                                time.sleep(delay_between_tabs)
                            except Exception as e_open_tab:
                                st.warning(f"UID '{uid_item}'ì˜ íƒ­ì„ ì—¬ëŠ” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e_open_tab}")
                                # ì¼ë¶€ íƒ­ ì—´ê¸° ì‹¤íŒ¨í•´ë„ ê³„ì† ì§„í–‰

                    if tabs_opened_count > 0:
                        st.success(f"ì´ {tabs_opened_count}ê°œì˜ ì¹´ì¹´ì˜¤í˜ì´ì§€ ê³µì§€ì‚¬í•­ íƒ­ì´ ìƒˆ íƒ­ìœ¼ë¡œ ì—´ë ¸ìŠµë‹ˆë‹¤ (ë˜ëŠ” ì—´ë„ë¡ ì‹œë„í–ˆìŠµë‹ˆë‹¤).")
                    else:
                        st.warning("íƒ­ì„ í•˜ë‚˜ë„ ì—´ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            else:
                st.warning(f"'{selected_csv_for_tabs}' íŒŒì¼ì´ ë¹„ì–´ìˆê±°ë‚˜ ìœ íš¨í•œ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        else:
            st.error(f"'{selected_csv_for_tabs}' íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. íŒŒì¼ ëª©ë¡ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")

st.markdown("---") # ë‹¤ìŒ ì„¹ì…˜ê³¼ êµ¬ë¶„

# ------------------------------------------------------------------------------
# ì•± í•˜ë‹¨ ì •ë³´ (ì„ íƒ ì‚¬í•­)
# ------------------------------------------------------------------------------
# st.markdown("---")
# st.caption("Pinsight Utility App")
# ------------------------------------------------------------------------------
# ì•± í•˜ë‹¨ ì •ë³´ (ì„ íƒ ì‚¬í•­)
# ------------------------------------------------------------------------------
st.markdown("---")
st.caption("Pinsight Utility App by YourName/Organization (ë¬¸ì˜: ...)")
